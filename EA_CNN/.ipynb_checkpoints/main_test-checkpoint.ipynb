{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from thop import profile\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from MadeData import MadeData\n",
    "from DNA import DNA\n",
    "from StructMutation import StructMutation\n",
    "\n",
    "# import global_var\n",
    "from global_var import DNA_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, DNA, parent_model=None):\n",
    "        super(Model, self).__init__()\n",
    "        self.dna = DNA\n",
    "        self.layer_vertex = torch.nn.ModuleList()\n",
    "        # print('init vertex', end='')\n",
    "        for i, vertex in enumerate(DNA.vertices):\n",
    "            # print('v{} '.format(i), end='')\n",
    "            # 默认第一层和最后一层 vertex 非 hidden 层\n",
    "            if vertex.type == 'bn_relu':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(torch.nn.BatchNorm2d(vertex.input_channel),\n",
    "                                        torch.nn.ReLU(inplace=True)))\n",
    "            elif vertex.type == 'Global Pooling':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(\n",
    "                        # torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                        torch.nn.Linear(vertex.input_channel, DNA.output_size_channel)))\n",
    "            else:\n",
    "                self.layer_vertex.append(None)\n",
    "\n",
    "        self.layer_edge = torch.nn.ModuleList()\n",
    "        # print('\\ninit edges', end='')\n",
    "        for i, edge in enumerate(DNA.edges):\n",
    "            # TODO: 默认padding补全\n",
    "            # print('e{}:'.format(i), end='')\n",
    "            if edge.type == 'conv':\n",
    "                # print('{},{},{} |'.format(edge.filter_half_height, edge.filter_half_width,edge.stride_scale),end=' ')\n",
    "                temp = torch.nn.Conv2d(edge.input_channel,\n",
    "                                       edge.output_channel,\n",
    "                                       kernel_size=(edge.filter_half_height * 2 + 1,\n",
    "                                                    edge.filter_half_width * 2 + 1),\n",
    "                                       stride=pow(2, edge.stride_scale),\n",
    "                                       padding=(edge.filter_half_height, edge.filter_half_width))\n",
    "                if edge.model_id != -1 or parent_model == None:\n",
    "                    temp.weight = parent_model.layer_edge[i].weight\n",
    "                self.layer_edge.append(temp)\n",
    "            else:\n",
    "                # print(end=' |')\n",
    "                self.layer_edge.append(None)\n",
    "        # print('')\n",
    "        self.batch_size = Evolution_pop.BATCH_SIZE\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        配置每层的 输入、输出、激活函数\n",
    "        '''\n",
    "        block_h = input.shape[0]\n",
    "        x = {\n",
    "            0: input,\n",
    "        }\n",
    "        for index, layer_vert in enumerate(self.layer_vertex[1:], start=1):\n",
    "            length = len(x)\n",
    "\n",
    "            a = torch.empty(block_h, 0, 0, 0)\n",
    "            for j, edg in enumerate(self.dna.vertices[index].edges_in):\n",
    "                ind_edg = self.dna.edges.index(edg)\n",
    "                ind_x = self.dna.vertices.index(edg.from_vertex)\n",
    "                t = x[ind_x]\n",
    "                if edg.type == 'conv':\n",
    "                    t = self.layer_edge[ind_edg](x[ind_x])\n",
    "                if j == 0:\n",
    "                    a = torch.empty(block_h, 0, t.shape[2], t.shape[3])\n",
    "                a = torch.cat((a, t), dim=1)\n",
    "\n",
    "            if self.dna.vertices[index].type == 'linear':\n",
    "                x[index] = a\n",
    "            elif self.dna.vertices[index].type == 'bn_relu':\n",
    "                x[index] = layer_vert(a)\n",
    "            elif self.dna.vertices[index].type == 'Global Pooling':\n",
    "                temp = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "                a = temp(a)\n",
    "                a = torch.squeeze(a, 3)\n",
    "                a = torch.squeeze(a, 2)\n",
    "                x[index] = layer_vert(a)\n",
    "\n",
    "        return x[len(x) - 1]\n",
    "\n",
    "\n",
    "class Evolution_pop:\n",
    "    _population_size_setpoint = 10\n",
    "    _evolve_time = 100\n",
    "    fitness_pool = []\n",
    "\n",
    "    EPOCH = 3  # 训练整批数据多少次\n",
    "    BATCH_SIZE = 50\n",
    "    N_CLASSES = 10\n",
    "\n",
    "    # LR = 0.001          # 学习率\n",
    "\n",
    "    def __init__(self, data, pop_max=10, evolve_time=100):\n",
    "        '''\n",
    "        初始化DNA: 一层hidden(节点数不同); 都为linear\n",
    "        接收传入的训练数据 data\n",
    "        初始化 Mutation 类\n",
    "        '''\n",
    "        self.population = []\n",
    "        self.model_stack = {}\n",
    "\n",
    "        for i in range(self._population_size_setpoint):\n",
    "            dna_iter = DNA()\n",
    "            self.population.append(dna_iter)\n",
    "            dna_iter.calculate_flow()\n",
    "            self.model_stack[dna_iter.dna_cnt] = Model(dna_iter)\n",
    "\n",
    "            global DNA_cnt\n",
    "            DNA_cnt = self._population_size_setpoint\n",
    "\n",
    "        self.data = data\n",
    "        self.struct_mutation = StructMutation()\n",
    "\n",
    "        self._population_size_setpoint = pop_max\n",
    "        self._evolve_time = evolve_time\n",
    "\n",
    "        self.fitness_dir = {}\n",
    "\n",
    "    def decode(self):\n",
    "        '''\n",
    "         对当前population队列中的每个未训练过的个体进行训练 \n",
    "         https://www.cnblogs.com/denny402/p/7520063.html\n",
    "        '''\n",
    "        for dna in self.population:\n",
    "            if dna.fitness != -1.0:\n",
    "                continue\n",
    "            # TODO: 新训练的个体将fitness加入fitness_pool\n",
    "            # dna.calculate_flow()\n",
    "            # net = Model(dna)\n",
    "\n",
    "            net = self.model_stack[dna.dna_cnt]\n",
    "            print(\"[decode].[\", dna.dna_cnt, \"]\", net)\n",
    "\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=dna.learning_rate)\n",
    "            # the target label is not one-hotted\n",
    "            loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_loader, testloader = self.data.getData()\n",
    "            # print(\"[Evolution_pop].[decode]->test_x: \", test_x.shape)\n",
    "            accuracy = 0\n",
    "            # training and testing\n",
    "            for epoch in range(self.EPOCH):\n",
    "                step = 0\n",
    "                # TODO: 用movan的enumerate会报错，why?\n",
    "                max_tep = int(60000 / train_loader.batch_size)\n",
    "\n",
    "                train_acc = .0\n",
    "                len_y = 0\n",
    "                for step, (b_x, b_y) in enumerate(train_loader):\n",
    "                    # print(\"[b_x, b_y].shape: \", b_x.shape, b_y.shape)\n",
    "                    # 分配 batch data, normalize x when iterate train_loader\n",
    "                    output = net(b_x)  # cnn output\n",
    "                    idy = b_y.view(-1, 1)\n",
    "                    # b_y = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, idy, 1).long()\n",
    "\n",
    "                    loss = loss_func(output, b_y)  # cross entropy loss\n",
    "                    # clear gradients for this training step\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()  # backpropagation, compute gradients\n",
    "                    optimizer.step()  # apply gradients\n",
    "\n",
    "                    if step % 50 == 0:\n",
    "                        pred = net(b_x)\n",
    "\n",
    "                        print(\"\\r\" + 'Epoch: ' + str(epoch) + ' step: ' + str(step) + '[' +\n",
    "                              \">>>\" * int(step / 50) + ']',\n",
    "                              end=' ')\n",
    "                        # print('loss: %.4f' % loss.data.numpy(), '| accuracy: %.4f' % accuracy, end=' ')\n",
    "                        print('loss: %.4f' % loss.data.numpy(), end=' ')\n",
    "                print('')\n",
    "\n",
    "            self.model_stack[dna.dna_cnt] = net\n",
    "            # evaluation--------------------------------\n",
    "            accuracy = self.Accuracy(net, testloader)\n",
    "            input = torch.randn(self.BATCH_SIZE, dna.input_size_channel, dna.input_size_height,\n",
    "                                dna.input_size_width)\n",
    "            flops, params = profile(net, inputs=(input, ))\n",
    "            print('----- Accuracy: {:.6f} Flops: {:.6f}-----'.format(accuracy, flops))\n",
    "            # dna.fitness = eval_acc / len_y\n",
    "            dna.fitness = accuracy\n",
    "            self.fitness_dir[dna.dna_cnt] = accuracy\n",
    "            print('')\n",
    "\n",
    "    def Accuracy(self, net, testloader):\n",
    "        ''' https://blog.csdn.net/Arctic_Beacon/article/details/85068188 '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "        class_correct = list(0. for i in range(self.N_CLASSES))\n",
    "        class_total = list(0. for i in range(self.N_CLASSES))\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == labels).squeeze()\n",
    "                for i in range(self.BATCH_SIZE):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        # for i in range(self.N_CLASSES):\n",
    "        #     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        return sum(class_correct) / sum(class_total)\n",
    "\n",
    "    def choose_varition_dna(self):\n",
    "        '''\n",
    "        每次挑选两个体,取fitness,判断要kill还是reproduce\n",
    "        '''\n",
    "        while self._evolve_time > 0:\n",
    "            self._evolve_time -= 1\n",
    "            self.decode()\n",
    "            # 每次挑两个个体并提取出训练成绩fitness\n",
    "            individual_pair = random.sample(list(enumerate(self.population)), 2)\n",
    "            # TODO: 话说他这样取出来如果删掉的话真的能保证吗\n",
    "            individual_pair.sort(key=lambda i: i[1].fitness, reverse=True)\n",
    "            # better_individual = individual_pair[0]\n",
    "            # worse_individual = individual_pair[1]\n",
    "            # print(\"Choice: \",self._evolve_time,end=' ')\n",
    "            # print(\"better: \",better_individual[0],'->',better_individual[1].fitness, end=' ')\n",
    "            # print(\"worse: \", worse_individual[0],'->', worse_individual[1].fitness, end=' ')\n",
    "            better_individual = individual_pair[0][0]\n",
    "            worse_individual = individual_pair[1][0]\n",
    "            individual_pair = []\n",
    "            # (population过大->kill不好的)，反之(population过小->reproduce好的)\n",
    "            if len(self.population) >= self._population_size_setpoint:\n",
    "                print(\"--kill worse\", worse_individual)\n",
    "                self._kill_individual(worse_individual)\n",
    "            elif len(self.population) < self._population_size_setpoint:\n",
    "                print(\"--reproduce better\", better_individual)\n",
    "                self._reproduce_and_train_individual(better_individual)\n",
    "        self.population.sort(key=lambda i: i.fitness, reverse=True)\n",
    "        print(self.population[0].fitness)\n",
    "        self.population[0].calculate_flow()\n",
    "        # self.pop_show()\n",
    "\n",
    "    def _kill_individual(self, index):\n",
    "        ''' kill by the index of population '''\n",
    "        # self._print_population()\n",
    "        if self.population[index].dna_cnt in self.model_stack:\n",
    "            del self.model_stack[self.population[index].dna_cnt]\n",
    "        del self.population[index]\n",
    "\n",
    "        # debug\n",
    "        # self._print_population()\n",
    "\n",
    "    def _reproduce_and_train_individual(self, index):\n",
    "        ''' \n",
    "        inherit the parent, mutate, join the population \n",
    "        为了节省时间实际上有 Weight Inheritance\n",
    "        '''\n",
    "        # self._print_population()\n",
    "\n",
    "        # inherit the parent (attention the dna_cnt)\n",
    "        son = self.inherit_DNA(self.population[index])\n",
    "\n",
    "        self.struct_mutation.mutate(son)\n",
    "        son.calculate_flow()\n",
    "        net = Model(son, self.model_stack[self.population[index].dna_cnt])\n",
    "\n",
    "        self.model_stack[son.dna_cnt] = net\n",
    "        self.population.append(son)\n",
    "        # debug\n",
    "        # self._print_population()\n",
    "\n",
    "    def inherit_DNA(self, dna):\n",
    "        ''' inderit from parent: reset dna_cnt, fitness '''\n",
    "        son = copy.deepcopy(dna)\n",
    "        global DNA_cnt\n",
    "        son.dna_cnt = DNA_cnt\n",
    "        DNA_cnt += 1\n",
    "        son.fitness = -1\n",
    "        return son\n",
    "\n",
    "    def _print_population(self):\n",
    "        print(\"pop sum: \", len(self.population), '|', end=' ')\n",
    "        index = 0\n",
    "        for i in self.population:\n",
    "            print('(', index, '->', i.dna_cnt, ')', end=' ')\n",
    "            index += 1\n",
    "        print('')\n",
    "\n",
    "    def pop_show(self):\n",
    "        ''' 画出种群变化分布图 '''\n",
    "        best_individual = self.population[0].dna_cnt\n",
    "        live_individual = []\n",
    "        for i in self.population:\n",
    "            live_individual.append(i.fitness)\n",
    "\n",
    "        global DNA_cnt\n",
    "        show_x = []\n",
    "        show_y = []\n",
    "        show_color = []\n",
    "        for i in range(DNA_cnt + 1):\n",
    "            if i in self.fitness_dir:\n",
    "                show_x.append(i)\n",
    "                show_y.append(self.fitness_dir[i])\n",
    "                if i in live_individual:\n",
    "                    if i == self.population[0].dna_cnt:\n",
    "                        show_color.append('red')\n",
    "                    else:\n",
    "                        show_color.append('blue')\n",
    "                else:\n",
    "                    show_color.append('gray')\n",
    "        plt.scatter(show_x, show_y, c=show_color, marker='.')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "DNA [ 7 ]销毁->fitness 0.26\n",
      "DNA [ 11 ]销毁->fitness 0.34\n",
      "DNA [ 13 ]销毁->fitness 0.38\n",
      "DNA [ 15 ]销毁->fitness 0.392\n",
      "DNA [ 16 ]销毁->fitness 0.38\n",
      "DNA [ 17 ]销毁->fitness -1\n",
      "[decode].[ 14 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2355  loss: 2.1712  loss: 2.0887  loss: 2.1116  loss: 2.0894  loss: 2.0345  loss: 2.0589  loss: 2.0246  loss: 1.9437  loss: 2.1221  loss: 2.0966  loss: 2.1866  loss: 2.1901  loss: 1.9637  loss: 2.1791  loss: 2.1310 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1325  loss: 1.9686  loss: 2.1484  loss: 2.0491  loss: 2.0349  loss: 2.0680  loss: 2.2040  loss: 2.0557  loss: 1.9854  loss: 2.0403  loss: 1.9448  loss: 2.1068  loss: 2.1839  loss: 1.8252  loss: 2.0989  loss: 2.0209 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9541  loss: 1.9994  loss: 2.1022  loss: 2.2152  loss: 1.7930  loss: 2.1569  loss: 1.8889  loss: 2.0825  loss: 2.1570  loss: 2.0277  loss: 2.0737  loss: 2.0929  loss: 2.0078  loss: 2.1940  loss: 2.1055  loss: 2.1837 \n",
      "----- Accuracy: 0.272000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 15 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9603  loss: 2.0758  loss: 2.1039  loss: 1.9960  loss: 2.0674  loss: 2.0732  loss: 2.1221  loss: 1.9746  loss: 2.1530  loss: 2.0821  loss: 2.0159  loss: 2.1419  loss: 1.9097  loss: 2.2553  loss: 2.0914  loss: 1.9850 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0281  loss: 2.2606  loss: 1.9150  loss: 1.9709  loss: 2.0770  loss: 1.9361  loss: 1.9977  loss: 2.0282  loss: 2.0682  loss: 2.1069  loss: 2.1076  loss: 2.0193  loss: 2.0298  loss: 2.1001  loss: 2.0997  loss: 2.0305 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2051  loss: 1.9881  loss: 2.0915  loss: 2.1921  loss: 2.1368  loss: 2.3323  loss: 1.9508  loss: 1.9493  loss: 2.0042  loss: 2.1374  loss: 1.9541  loss: 2.2099  loss: 2.0483  loss: 2.1734  loss: 2.0039  loss: 2.1243 \n",
      "----- Accuracy: 0.236000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 16 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1752  loss: 2.0406  loss: 2.2377  loss: 2.0101  loss: 2.0710  loss: 2.0191  loss: 2.1652  loss: 2.1585  loss: 2.1895  loss: 2.0108  loss: 2.1601  loss: 1.9340  loss: 2.0672  loss: 2.0316  loss: 2.2095  loss: 2.1809 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0456  loss: 2.1848  loss: 2.1114  loss: 2.1668  loss: 2.0306  loss: 2.0526  loss: 1.9282  loss: 2.0213  loss: 2.1103  loss: 1.9673  loss: 2.0612  loss: 2.1214  loss: 2.1459  loss: 1.9742  loss: 2.1664  loss: 2.0317 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0496  loss: 2.0715  loss: 1.9417  loss: 2.1550  loss: 2.0016  loss: 2.2072  loss: 2.3057  loss: 2.2537  loss: 2.1364  loss: 2.1545  loss: 2.0904  loss: 2.2035  loss: 2.0695  loss: 2.2497  loss: 1.9478  loss: 2.0810 \n",
      "----- Accuracy: 0.252000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 17 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1792  loss: 2.0705  loss: 2.1556  loss: 2.0236  loss: 2.0981  loss: 1.9929  loss: 2.0692  loss: 2.1112  loss: 1.9647  loss: 1.9379  loss: 2.0504  loss: 2.0204  loss: 1.9382  loss: 2.2047  loss: 2.1671  loss: 2.1573 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.3197  loss: 1.9743  loss: 2.2066  loss: 1.9789  loss: 2.0326  loss: 2.1386  loss: 1.9968  loss: 2.0484  loss: 2.0492  loss: 2.2077  loss: 1.9752  loss: 2.0421  loss: 2.2901  loss: 2.0752  loss: 2.0468  loss: 2.2339 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1063  loss: 1.9530  loss: 2.1720  loss: 1.9381  loss: 2.0165  loss: 2.1516  loss: 2.1348  loss: 2.1161  loss: 2.1411  loss: 2.0207  loss: 2.0142  loss: 2.0478  loss: 1.9770  loss: 2.0439  loss: 2.1019  loss: 2.1370 \n",
      "----- Accuracy: 0.292000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 18 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1282  loss: 2.1158  loss: 2.0975  loss: 2.0998  loss: 2.1613  loss: 2.0718  loss: 2.1393  loss: 2.1172  loss: 2.0169  loss: 2.1456  loss: 2.0465  loss: 2.2013  loss: 2.1434  loss: 2.1386  loss: 2.1489  loss: 2.0283 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1849  loss: 1.9213  loss: 2.0809  loss: 2.1084  loss: 2.1989  loss: 2.1178  loss: 2.0647  loss: 2.1789  loss: 2.1261  loss: 2.1260  loss: 2.0327  loss: 2.0320  loss: 2.2999  loss: 1.9706  loss: 2.1015  loss: 1.9859 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9741  loss: 2.1299  loss: 2.2054  loss: 2.0258  loss: 2.0272  loss: 1.9437  loss: 2.0731  loss: 2.0659  loss: 2.1000  loss: 1.9175  loss: 1.9047  loss: 2.0366  loss: 2.0600  loss: 2.1840  loss: 2.0742  loss: 2.0460 \n",
      "----- Accuracy: 0.244000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 19 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1790  loss: 2.0901  loss: 2.0504  loss: 2.0626  loss: 2.1633  loss: 2.0388  loss: 2.0284  loss: 2.0965  loss: 2.0083  loss: 2.0485  loss: 1.9508  loss: 1.9508  loss: 2.0124  loss: 1.9739  loss: 2.1802  loss: 1.9437 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0672  loss: 2.0306  loss: 2.1265  loss: 2.0688  loss: 2.2649  loss: 1.9934  loss: 1.9077  loss: 2.1194  loss: 2.2007  loss: 1.9789  loss: 2.1427  loss: 2.0404  loss: 1.9755  loss: 2.1930  loss: 2.0354  loss: 2.0413 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9064  loss: 2.0451  loss: 2.0244  loss: 2.1640  loss: 1.9898  loss: 2.1686  loss: 1.9416  loss: 1.9657  loss: 2.0309  loss: 2.1469  loss: 1.9336  loss: 2.0655  loss: 2.5038  loss: 2.1229  loss: 2.2783  loss: 2.0352 \n",
      "----- Accuracy: 0.244000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 20 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1162  loss: 2.0176  loss: 2.0431  loss: 2.0549  loss: 2.2135  loss: 2.1740  loss: 2.0007  loss: 2.0868  loss: 1.9538  loss: 1.9207  loss: 2.1022  loss: 2.0712  loss: 2.1217  loss: 2.2292  loss: 2.1220  loss: 1.9585 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0424  loss: 2.0535  loss: 2.0863  loss: 2.1314  loss: 2.0375  loss: 2.0285  loss: 2.0986  loss: 2.0216  loss: 2.0764  loss: 1.9615  loss: 2.0921  loss: 2.0169  loss: 2.1286  loss: 2.0972  loss: 2.1571  loss: 1.9435 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0535  loss: 1.9760  loss: 2.2977  loss: 2.0447  loss: 2.2558  loss: 1.9403  loss: 2.0696  loss: 2.1295  loss: 2.1873  loss: 2.2811  loss: 2.0478  loss: 2.1239  loss: 2.0360  loss: 2.2074  loss: 2.1438  loss: 1.9728 \n",
      "----- Accuracy: 0.260000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 21 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0574  loss: 2.0700  loss: 2.0358  loss: 2.0215  loss: 2.2944  loss: 2.0328  loss: 2.0237  loss: 2.1586  loss: 2.0845  loss: 1.9323  loss: 1.9074  loss: 2.0457  loss: 2.0078  loss: 2.1487  loss: 2.0466  loss: 2.1609 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.3458  loss: 1.8586  loss: 1.9875  loss: 1.9726  loss: 2.0323  loss: 2.1598  loss: 2.2183  loss: 2.0192  loss: 1.9726  loss: 2.0252  loss: 2.1562  loss: 1.9951  loss: 2.0978  loss: 2.1151  loss: 2.0527  loss: 2.0071 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2108  loss: 2.1760  loss: 2.0078  loss: 2.1560  loss: 2.1400  loss: 2.0765  loss: 2.1247  loss: 2.1508  loss: 2.0798  loss: 1.9739  loss: 2.1164  loss: 2.1294  loss: 2.0178  loss: 2.1754  loss: 2.0376  loss: 2.0712 \n",
      "----- Accuracy: 0.212000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 22 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1721  loss: 2.1085  loss: 2.1589  loss: 2.1829  loss: 2.2184  loss: 2.0844  loss: 2.0365  loss: 1.9139  loss: 2.1491  loss: 2.0673  loss: 2.1051  loss: 2.3089  loss: 2.1453  loss: 1.9269  loss: 2.0201  loss: 2.1990 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1935  loss: 2.0718  loss: 2.0210  loss: 2.1996  loss: 2.1033  loss: 2.1369  loss: 2.1656  loss: 2.0801  loss: 2.1790  loss: 2.0344  loss: 2.0878  loss: 2.0237  loss: 2.0568  loss: 2.1153  loss: 2.2032  loss: 2.0840 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0128  loss: 1.9280  loss: 2.1730  loss: 2.0571  loss: 2.1728  loss: 2.0339  loss: 2.2121  loss: 2.1187  loss: 2.1245  loss: 2.2416  loss: 2.0183  loss: 2.0921  loss: 2.2638  loss: 2.1908  loss: 2.0236  loss: 2.0301 \n",
      "----- Accuracy: 0.240000 Flops: 3000.000000-----\n",
      "\n",
      "[decode].[ 23 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0191  loss: 2.1162  loss: 2.0115  loss: 2.1577  loss: 2.0801  loss: 2.2057  loss: 2.1337  loss: 2.1698  loss: 2.1043  loss: 2.0887  loss: 1.9780  loss: 2.0263  loss: 2.0781  loss: 2.0839  loss: 2.1137  loss: 1.9703 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1195  loss: 1.9307  loss: 2.1252  loss: 2.0916  loss: 1.8815  loss: 2.0945  loss: 2.1366  loss: 2.1132  loss: 2.1831  loss: 1.9798  loss: 2.0571  loss: 2.2247  loss: 2.2087  loss: 2.2375  loss: 2.1620  loss: 2.2305 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1541  loss: 2.0541  loss: 2.2321  loss: 2.3258  loss: 2.2208  loss: 2.1208  loss: 2.0161  loss: 2.0154  loss: 2.0388  loss: 2.1827  loss: 1.9843  loss: 2.0582  loss: 2.2204  loss: 1.9900  loss: 1.9579  loss: 2.0225 \n",
      "----- Accuracy: 0.264000 Flops: 3000.000000-----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 14 ]销毁->fitness 0.272\n",
      "--reproduce better 7\n",
      "[add_edge]->conv: 0 2\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 0.c_s0,1,1 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 10 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0517  loss: 2.1861  loss: 2.1105  loss: 2.0630  loss: 2.2003  loss: 2.0906  loss: 2.1659  loss: 2.1168  loss: 2.1747  loss: 2.2555  loss: 2.1284  loss: 2.1803  loss: 2.1534  loss: 2.0596  loss: 2.0369  loss: 1.9228 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0214  loss: 2.2107  loss: 2.2305  loss: 2.1648  loss: 2.1082  loss: 1.9195  loss: 2.0517  loss: 2.1574  loss: 2.0588  loss: 2.0224  loss: 1.9482  loss: 2.1790  loss: 2.1719  loss: 2.0002  loss: 1.8989  loss: 2.1412 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9195  loss: 1.8671  loss: 1.9331  loss: 1.8905  loss: 2.2235  loss: 2.1549  loss: 2.3179  loss: 2.1538  loss: 2.1214  loss: 1.9284  loss: 2.0577  loss: 1.8882  loss: 1.9983  loss: 2.2419  loss: 2.1072  loss: 2.1083 \n",
      "----- Accuracy: 0.256000 Flops: 4306800.000000-----\n",
      "\n",
      "--kill worse 9\n",
      "DNA [ 10 ]销毁->fitness 0.256\n",
      "--reproduce better 1\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.c_s0,1,1 \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 11 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9362  loss: 2.0526  loss: 2.2861  loss: 2.2625  loss: 2.2682  loss: 1.9319  loss: 2.0190  loss: 2.2153  loss: 2.0774  loss: 2.0611  loss: 2.1066  loss: 2.0557  loss: 2.0132  loss: 2.2675  loss: 2.3326  loss: 1.9965 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0908  loss: 2.3130  loss: 2.1354  loss: 1.9591  loss: 2.2016  loss: 2.0543  loss: 2.1831  loss: 2.2367  loss: 2.0432  loss: 1.9225  loss: 2.1187  loss: 1.9268  loss: 2.3312  loss: 2.2187  loss: 2.0874  loss: 2.0221 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0553  loss: 2.1976  loss: 2.2208  loss: 2.0961  loss: 2.1955  loss: 2.1445  loss: 2.2512  loss: 2.0759  loss: 2.1499  loss: 2.1614  loss: 2.0855  loss: 1.9378  loss: 2.1099  loss: 2.1272  loss: 2.2972  loss: 2.0794 \n",
      "----- Accuracy: 0.208000 Flops: 4303800.000000-----\n",
      "\n",
      "--kill worse 7\n",
      "DNA [ 22 ]销毁->fitness 0.24\n",
      "--reproduce better 2\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 12 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=11, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0548  loss: 1.7313  loss: 1.9530  loss: 1.6978  loss: 1.7217  loss: 1.6980  loss: 1.7402  loss: 1.8395  loss: 1.8626  loss: 1.7452  loss: 1.8542  loss: 1.7704  loss: 1.7378  loss: 1.6946  loss: 1.6442  loss: 1.8526 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6671  loss: 1.9676  loss: 1.5197  loss: 1.7436  loss: 1.6865  loss: 1.8050  loss: 1.6949  loss: 1.6324  loss: 1.8865  loss: 1.7494  loss: 1.6486  loss: 1.7720  loss: 1.7702  loss: 1.6687  loss: 1.8987  loss: 1.6086 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.5841  loss: 1.8754  loss: 1.9675  loss: 1.6141  loss: 1.7802  loss: 1.7503  loss: 1.6384  loss: 1.6249  loss: 1.7904  loss: 1.7774  loss: 1.6263  loss: 1.6203  loss: 2.0349  loss: 1.7367  loss: 1.6570  loss: 1.8937 \n",
      "----- Accuracy: 0.344000 Flops: 16907000.000000-----\n",
      "\n",
      "--kill worse 6\n",
      "DNA [ 21 ]销毁->fitness 0.212\n",
      "--reproduce better 2\n",
      "[add_edge]->identity: 0 2\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 0.i_s0,N,N , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 13 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1214  loss: 2.0118  loss: 2.1876  loss: 2.0477  loss: 2.0290  loss: 2.1466  loss: 2.0612  loss: 2.0291  loss: 2.2479  loss: 2.1993  loss: 2.2097  loss: 2.0805  loss: 1.9673  loss: 2.0354  loss: 2.1382  loss: 2.1862 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9845  loss: 2.1749  loss: 2.1261  loss: 2.1205  loss: 2.0681  loss: 2.0490  loss: 2.0870  loss: 2.2413  loss: 2.0807  loss: 2.0578  loss: 2.1228  loss: 1.9432  loss: 2.1620  loss: 1.9583  loss: 2.0357  loss: 1.9688 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9434  loss: 1.9605  loss: 1.9579  loss: 2.1113  loss: 1.9919  loss: 2.0397  loss: 2.2255  loss: 1.8576  loss: 2.1119  loss: 2.0025  loss: 2.0469  loss: 1.8743  loss: 2.0489  loss: 1.9291  loss: 1.9579  loss: 2.0234 \n",
      "----- Accuracy: 0.260000 Flops: 6000.000000-----\n",
      "\n",
      "--kill worse 7\n",
      "DNA [ 11 ]销毁->fitness 0.208\n",
      "--reproduce better 6\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 14 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.3385  loss: 2.3756  loss: 2.2491  loss: 2.1461  loss: 2.0474  loss: 2.1105  loss: 2.1334  loss: 2.2197  loss: 2.1221  loss: 2.0821  loss: 2.2023  loss: 2.4022  loss: 1.9806  loss: 1.9774  loss: 2.0275  loss: 1.9800 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2166  loss: 2.4945  loss: 2.0506  loss: 2.1237  loss: 2.1005  loss: 2.1247  loss: 2.0068  loss: 1.8857  loss: 2.1919  loss: 2.1033  loss: 2.1233  loss: 2.0829  loss: 2.2647  loss: 2.0282  loss: 2.1024  loss: 2.1917 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0120  loss: 1.9255  loss: 2.1166  loss: 2.0738  loss: 2.0575  loss: 2.2406  loss: 2.0497  loss: 2.0021  loss: 2.1681  loss: 2.0555  loss: 1.9800  loss: 2.2356  loss: 2.1847  loss: 2.4222  loss: 2.0391  loss: 2.0158 \n",
      "----- Accuracy: 0.284000 Flops: 14346000.000000-----\n",
      "\n",
      "--kill worse 1\n",
      "DNA [ 16 ]销毁->fitness 0.252\n",
      "--reproduce better 4\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 15 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0749  loss: 2.1034  loss: 2.1331  loss: 2.0608  loss: 2.1179  loss: 2.1713  loss: 2.0953  loss: 2.1189  loss: 2.2775  loss: 2.0979  loss: 2.1785  loss: 2.0428  loss: 1.9819  loss: 2.0942  loss: 2.0525  loss: 2.1226 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1148  loss: 2.0752  loss: 2.1314  loss: 2.0882  loss: 2.1286  loss: 2.2753  loss: 2.1228  loss: 2.0306  loss: 2.0301  loss: 1.9630  loss: 1.9664  loss: 2.1443  loss: 2.1848  loss: 2.1830  loss: 2.2143  loss: 2.0332 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0613  loss: 2.0378  loss: 2.1234  loss: 2.0120  loss: 2.1506  loss: 2.1758  loss: 2.1443  loss: 1.9326  loss: 2.0830  loss: 1.9851  loss: 2.1303  loss: 2.0361  loss: 1.9769  loss: 2.2725  loss: 2.0834  loss: 1.9997 \n",
      "----- Accuracy: 0.268000 Flops: 3000.000000-----\n",
      "\n",
      "--kill worse 7\n",
      "DNA [ 13 ]销毁->fitness 0.26\n",
      "--reproduce better 4\n",
      "[add_edge]->conv: 0 2\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 0.c_s0,1,1 , 1.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 16 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0135  loss: 2.1200  loss: 1.9904  loss: 2.0200  loss: 2.1600  loss: 2.0012  loss: 2.0182  loss: 2.0665  loss: 2.1326  loss: 1.9866  loss: 2.2126  loss: 2.2054  loss: 2.1052  loss: 1.9295  loss: 2.0907  loss: 1.9493 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1733  loss: 2.0820  loss: 1.9057  loss: 2.1786  loss: 2.2870  loss: 2.0231  loss: 2.0671  loss: 2.0275  loss: 2.2344  loss: 2.0445  loss: 2.0033  loss: 1.9777  loss: 2.1393  loss: 2.0365  loss: 2.0249  loss: 1.9521 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0619  loss: 1.8824  loss: 2.1111  loss: 1.9666  loss: 2.0434  loss: 2.3625  loss: 1.9068  loss: 2.3083  loss: 1.9010  loss: 2.0337  loss: 1.9314  loss: 2.0490  loss: 2.0613  loss: 1.9323  loss: 1.9989  loss: 1.9858 \n",
      "----- Accuracy: 0.312000 Flops: 7176000.000000-----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 20 ]销毁->fitness 0.26\n",
      "--reproduce better 8\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N , 0.c_s0,1,1 \n",
      "[calculate_flow] finish\n",
      "[decode].[ 17 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=13, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9769  loss: 2.0717  loss: 1.9147  loss: 1.8711  loss: 1.8526  loss: 1.9643  loss: 1.8301  loss: 1.9093  loss: 1.7681  loss: 1.9480  loss: 1.8804  loss: 1.6191  loss: 1.6671  loss: 1.6246  loss: 1.5734  loss: 1.9284 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.7883  loss: 1.7175  loss: 1.7656  loss: 1.9284  loss: 1.7611  loss: 1.8798  loss: 1.8823  loss: 1.6340  loss: 1.7612  loss: 1.7419  loss: 1.7083  loss: 1.7497  loss: 1.6480  loss: 1.5769  loss: 1.9028  loss: 1.8981 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6997  loss: 1.6242  loss: 1.5106  loss: 1.5915  loss: 1.8625  loss: 1.7436  loss: 1.7711  loss: 1.7147  loss: 1.7058  loss: 1.8006  loss: 1.8261  loss: 1.7833  loss: 1.6579  loss: 1.5881  loss: 1.5231  loss: 1.7482 \n",
      "----- Accuracy: 0.376000 Flops: 19469000.000000-----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 23 ]销毁->fitness 0.264\n",
      "--reproduce better 5\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 18 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2726  loss: 2.1902  loss: 2.3269  loss: 2.3860  loss: 2.2160  loss: 2.1176  loss: 2.1847  loss: 2.0394  loss: 1.9746  loss: 2.4042  loss: 2.0576  loss: 2.3669  loss: 2.1839  loss: 2.0699  loss: 2.1473  loss: 2.3587 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0853  loss: 2.1538  loss: 2.2894  loss: 2.1157  loss: 2.0648  loss: 2.0828  loss: 2.0034  loss: 2.2547  loss: 2.1556  loss: 2.0382  loss: 2.1878  loss: 2.2314  loss: 1.9645  loss: 2.1466  loss: 2.0871  loss: 1.8989 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9513  loss: 1.9579  loss: 2.3239  loss: 1.8664  loss: 2.2367  loss: 2.0074  loss: 2.2431  loss: 2.5019  loss: 2.1593  loss: 1.9882  loss: 1.9827  loss: 2.1402  loss: 2.1784  loss: 2.0003  loss: 2.1329  loss: 2.1308 \n",
      "----- Accuracy: 0.248000 Flops: 14346000.000000-----\n",
      "\n",
      "--kill worse 9\n",
      "DNA [ 18 ]销毁->fitness 0.248\n",
      "--reproduce better 4\n",
      "[add_edge]->conv: 0 2\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 , 0.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 19 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=14, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0601  loss: 1.9459  loss: 1.9382  loss: 2.0179  loss: 1.8956  loss: 1.7197  loss: 1.7355  loss: 1.8808  loss: 1.8110  loss: 1.6591  loss: 1.9525  loss: 1.9114  loss: 1.7975  loss: 1.7083  loss: 1.8714  loss: 1.9036 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6945  loss: 2.1277  loss: 1.7989  loss: 1.9594  loss: 1.7997  loss: 1.8256  loss: 1.7415  loss: 1.9411  loss: 1.7195  loss: 1.5412  loss: 1.7328  loss: 1.7048  loss: 1.7171  loss: 1.7393  loss: 1.7844  loss: 1.6312 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.7429  loss: 1.5658  loss: 1.7936  loss: 1.7364  loss: 1.6763  loss: 1.7637  loss: 1.8547  loss: 1.7313  loss: 1.5338  loss: 1.6966  loss: 1.7031  loss: 1.5198  loss: 1.5750  loss: 1.5662  loss: 1.8955  loss: 1.6528 \n",
      "----- Accuracy: 0.408000 Flops: 21518000.000000-----\n",
      "\n",
      "--kill worse 7\n",
      "DNA [ 16 ]销毁->fitness 0.312\n",
      "--reproduce better 7\n",
      "[add_edge]->identity: 1 3\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.c_s0,1,1 \n",
      "vertex [ 2 ].0 , 1.i_s0,N,N \n",
      "vertex [ 3 ].0 , 2.c_s0,1,1 \n",
      "vertex [ 4 ].0 , 2.i_s0,N,N , 0.c_s0,1,1 , 3.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 20 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): Sequential(\n",
      "      (0): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=28, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(6, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2125  loss: 1.8499  loss: 1.6434  loss: 1.6544  loss: 2.1051  loss: 2.0307  loss: 1.8736  loss: 2.1317  loss: 1.9918  loss: 1.7457  loss: 2.1263  loss: 2.0310  loss: 1.6803  loss: 2.1424  loss: 1.8246  loss: 1.5952 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6520  loss: 1.8163  loss: 1.6530  loss: 1.4994  loss: 1.6908  loss: 1.8583  loss: 1.5590  loss: 1.6045  loss: 1.6962  loss: 1.6624  loss: 1.6122  loss: 1.3456  loss: 1.3332  loss: 1.6777  loss: 1.6338  loss: 1.7217 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.5612  loss: 1.5553  loss: 1.4012  loss: 1.6986  loss: 1.8313  loss: 1.4762  loss: 1.6980  loss: 1.7916  loss: 1.3329  loss: 1.7685  loss: 1.3835  loss: 1.6455  loss: 1.5426  loss: 1.3856  loss: 1.4561  loss: 1.8817 \n",
      "----- Accuracy: 0.404000 Flops: 66024800.000000-----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 15 ]销毁->fitness 0.236\n",
      "--reproduce better 6\n",
      "outputs_mutable 0 1\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 2.c_s0,1,1 \n",
      "vertex [ 4 ].0 , 3.i_s0,N,N , 0.c_s0,1,1 \n",
      "[calculate_flow] finish\n",
      "[decode].[ 21 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=36, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(8, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9355  loss: 1.8985  loss: 1.8546  loss: 1.8612  loss: 1.7337  loss: 1.6580  loss: 1.6448  loss: 2.0699  loss: 1.6634  loss: 1.7220  loss: 1.6564  loss: 1.6410  loss: 1.6285  loss: 1.5687  loss: 1.9134  loss: 1.7352 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.2247  loss: 1.3443  loss: 1.6532  loss: 1.7458  loss: 1.4879  loss: 1.5411  loss: 1.4496  loss: 1.6940  loss: 1.6992  loss: 1.5788  loss: 1.5245  loss: 1.5426  loss: 1.3426  loss: 1.6693  loss: 1.7373  loss: 1.7235 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.4735  loss: 1.4971  loss: 1.3295  loss: 1.2071  loss: 1.6195  loss: 1.3960  loss: 1.4128  loss: 1.4781  loss: 1.7585  loss: 1.4461  loss: 1.6701  loss: 1.3889  loss: 1.3329  loss: 1.5385  loss: 1.2562  loss: 1.5678 \n",
      "----- Accuracy: 0.504000 Flops: 138532000.000000-----\n",
      "\n",
      "--kill worse 3\n",
      "DNA [ 12 ]销毁->fitness 0.344\n",
      "--reproduce better 0\n",
      "[add_edge]->conv: 0 2\n",
      "outputs_mutable 0 0\n",
      "vertex [ 1 ].0 , 0.i_s0,N,N \n",
      "vertex [ 2 ].0 , 1.c_s0,1,1 \n",
      "vertex [ 3 ].0 , 0.c_s0,1,1 , 2.i_s0,N,N \n",
      "[calculate_flow] finish\n",
      "[decode].[ 22 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0416  loss: 2.1362  loss: 2.1820  loss: 2.0616  loss: 2.2326  loss: 1.9326  loss: 1.9712  loss: 2.1452  loss: 2.1729  loss: 2.1606  loss: 2.1061  loss: 2.2984  loss: 2.0570  loss: 2.0363  loss: 1.8804  loss: 2.0098 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9629  loss: 1.9940  loss: 1.9387  loss: 1.9610  loss: 1.8476  loss: 1.9594  loss: 2.1090  loss: 2.0286  loss: 2.0706  loss: 1.9666  loss: 2.0598  loss: 2.0824  loss: 2.1002  loss: 2.1584  loss: 2.1015  loss: 2.2557 \n",
      "Epoch: 2 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0002  loss: 2.1382  loss: 1.9054  loss: 1.9210  loss: 2.1437  loss: 2.1774  loss: 1.7973  loss: 1.9094  loss: 1.9881  loss: 2.0600  loss: 2.2481  loss: 2.0109  loss: 1.9522  loss: 1.9311  loss: 1.7405  loss: 1.8199 \n",
      "----- Accuracy: 0.256000 Flops: 11476800.000000-----\n",
      "\n",
      "--kill worse 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fe4443bb5ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# test = Evolution_pop(train_loader, test_x, test_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvolution_pop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpop_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevolve_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_varition_dna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-63b5a616122d>\u001b[0m in \u001b[0;36mchoose_varition_dna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_population_size_setpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--kill worse\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworse_individual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kill_individual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworse_individual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_population_size_setpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--reproduce better\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter_individual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-63b5a616122d>\u001b[0m in \u001b[0;36m_kill_individual\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# self._print_population()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_stack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdna_cnt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 18"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = MadeData()\n",
    "    # 数据集选择\n",
    "    train_loader, testloader = data.CIFR10()\n",
    "\n",
    "    # test = Evolution_pop(train_loader, test_x, test_y)\n",
    "    test = Evolution_pop(data, pop_max=10, evolve_time=100)\n",
    "    test.choose_varition_dna()\n",
    "    test.pop_show()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable         Type             Data/Info\n",
      "-------------------------------------------\n",
      "DNA              type             <class 'DNA.DNA'>\n",
      "DNA_cnt          int              23\n",
      "Data             module           <module 'torch.utils.data<...>tils\\\\data\\\\__init__.py'>\n",
      "Evolution_pop    type             <class '__main__.Evolution_pop'>\n",
      "F                module           <module 'torch.nn.functio<...>orch\\\\nn\\\\functional.py'>\n",
      "MadeData         type             <class 'MadeData.MadeData'>\n",
      "Model            type             <class '__main__.Model'>\n",
      "StructMutation   type             <class 'StructMutation.StructMutation'>\n",
      "copy             module           <module 'copy' from 'D:\\\\<...>anaconda3\\\\lib\\\\copy.py'>\n",
      "data             MadeData         <MadeData.MadeData object at 0x000001F70CB15908>\n",
      "math             module           <module 'math' (built-in)>\n",
      "np               module           <module 'numpy' from 'D:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "os               module           <module 'os' from 'D:\\\\so<...>\\\\anaconda3\\\\lib\\\\os.py'>\n",
      "plt              module           <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "profile          function         <function profile at 0x000001F70BBF0D90>\n",
      "random           module           <module 'random' from 'D:<...>aconda3\\\\lib\\\\random.py'>\n",
      "test             Evolution_pop    <__main__.Evolution_pop o<...>ct at 0x000001F70CB15F60>\n",
      "testloader       DataLoader       <torch.utils.data.dataloa<...>ct at 0x000001F70CB15E48>\n",
      "torch            module           <module 'torch' from 'D:\\<...>ges\\\\torch\\\\__init__.py'>\n",
      "train_loader     DataLoader       <torch.utils.data.dataloa<...>ct at 0x000001F70E7B6588>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
