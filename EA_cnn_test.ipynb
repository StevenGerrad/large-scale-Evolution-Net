{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set contains the following mutations:\n",
    "\n",
    "# • 学习率 ALTER-LEARNING-RATE (sampling details below).\n",
    "# • 线性 IDENTITY (effectively means “keep training”).\n",
    "# • 权重 RESET-WEIGHTS (sampled as in He et al. (2015), for\n",
    "#       example).\n",
    "# • 增 INSERT-CONVOLUTION (inserts a convolution at a random location in the “convolutional\n",
    "#       backbone”, as in Figure 1. The inserted convolution has 3 × 3 filters, strides\n",
    "#       of 1 or 2 at random, number of channels same as input.May apply batch-normalization\n",
    "#       and ReLU activation or none at random).\n",
    "# • 删 REMOVE-CONVOLUTION.\n",
    "# • 步长 ALTER-STRIDE (only powers of 2 are allowed).\n",
    "# • 通道数 ALTER-NUMBER-OF-CHANNELS (of random conv.).\n",
    "# • 滤波器大小 FILTER-SIZE (horizontal or vertical at random, on random convolution, odd values only).\n",
    "# • INSERT-ONE-TO-ONE (inserts a one-to-one/identity\n",
    "#       connection, analogous to insert-convolution mutation).\n",
    "# • 增跳层 ADD-SKIP (identity between random layers).\n",
    "# • 删跳层 REMOVE-SKIP (removes random skip).\n",
    "\n",
    "# 主要的组合实际为: conv+bn+relu\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# OUR--MLP\n",
    "\n",
    "# 学习率α\n",
    "# 增layer\n",
    "# 增skip\n",
    "# 设置'linear'/'relu'\n",
    "\n",
    "# 设置layer:\n",
    "#   out_channels\n",
    "#   kernel_size\n",
    "#   stride\n",
    "#   padding\n",
    "\n",
    "# 1.每次挑选两个个体, 确保个体已经被训练过了\n",
    "# 2.挑选个体的fitness，(population过大->kill不好的)，反之(population过小->reproduce好的)\n",
    "\n",
    "# Questiuon:\n",
    "# 1. depth_factor 来决定channel, channel要是变小那么depth_factor是小数？若乘积结果不是整数需要取整\n",
    "# 2. 仍要控制输出分类结果为one-hot\n",
    "# 3. 是否默认维持 padding : 是\n",
    "\n",
    "# ATTENTION\n",
    "# 1.sride 应为0，这样才不会收缩 (2^0 = 1)\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "DNA_cnt = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DNA(object):\n",
    "    '''\n",
    "    learning_rate, vertices[vertex_id]+type, edges[edge_id]\n",
    "    由vertex(linear / bn_relu), 和 edge(conv / identity)组成\n",
    "    '''\n",
    "    # __dna_cnt = 0\n",
    "    input_size_height = 32\n",
    "    input_size_width = 32\n",
    "    input_size_channel = 3\n",
    "\n",
    "    output_size_height = 1\n",
    "    output_size_width = 1\n",
    "    output_size_channel = 10\n",
    "\n",
    "    def __init__(self, learning_rate=0.05):\n",
    "        '''\n",
    "        注意，vertice 和 edges 中应该存引用\n",
    "        '''\n",
    "        global DNA_cnt\n",
    "        self.dna_cnt = DNA_cnt\n",
    "        DNA_cnt += 1\n",
    "        self.fitness = -1.0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # input layer\n",
    "        l0 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='linear',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        # Global Pooling layer\n",
    "        l1 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='linear',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        # output layer\n",
    "        l2 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='Global Pooling',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        self.vertices = []\n",
    "        self.vertices.append(l0)\n",
    "        self.vertices.append(l1)\n",
    "        self.vertices.append(l2)\n",
    "\n",
    "        # edge\n",
    "        edg1 = Edge(from_vertex=l0, to_vertex=l1, type='identity')\n",
    "        edg2 = Edge(from_vertex=l1, to_vertex=l2, type='identity')\n",
    "\n",
    "        edg1.input_channel = self.input_size_channel\n",
    "        edg1.output_channel = self.input_size_channel\n",
    "        self.edges = []\n",
    "        self.edges.append(edg1)\n",
    "        self.edges.append(edg2)\n",
    "\n",
    "        l0.edges_out.add(edg1)\n",
    "        l1.edges_in.add(edg1), l1.edges_out.add(edg2)\n",
    "        l2.edges_in.add(edg2)\n",
    "\n",
    "    def __del__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        print(class_name, \"[\", self.dna_cnt, \"]销毁->fitness\", self.fitness, end='\\n')\n",
    "\n",
    "    def add_edge(self,\n",
    "                 from_vertex_id,\n",
    "                 to_vertex_id,\n",
    "                 edge_type='identity',\n",
    "                 depth_factor=1,\n",
    "                 filter_half_width=None,\n",
    "                 filter_half_height=None,\n",
    "                 stride_scale=0):\n",
    "        \"\"\"\n",
    "        Adds an edge to the DNA graph, ensuring internal consistency.\n",
    "        \"\"\"\n",
    "        edge = Edge(from_vertex=self.vertices[from_vertex_id],\n",
    "                    to_vertex=self.vertices[to_vertex_id],\n",
    "                    type=edge_type,\n",
    "                    depth_factor=depth_factor,\n",
    "                    filter_half_width=filter_half_width,\n",
    "                    filter_half_height=filter_half_height,\n",
    "                    stride_scale=stride_scale)\n",
    "        self.edges.append(edge)\n",
    "        self.vertices[from_vertex_id].edges_out.add(edge)\n",
    "        self.vertices[to_vertex_id].edges_in.add(edge)\n",
    "        return edge\n",
    "\n",
    "    def calculate_flow(self):\n",
    "        '''\n",
    "        按顺序计算神经网络每层的输入输出参数\n",
    "        '''\n",
    "        self.vertices[0].input_channel = self.input_size_channel\n",
    "        # self.vertices[0].output_channel = self.input_size_channel\n",
    "        # self.vertices[-1].input_channel = self.output_size_channel\n",
    "        # self.vertices[-1].output_channel = self.output_size_channel\n",
    "\n",
    "        for i, vertex in enumerate(self.vertices[1:], start=1):\n",
    "            vertex.input_channel = 0\n",
    "            print('vertex [', i, '].{}'.format(vertex.input_channel), end=' ')\n",
    "            for edge in vertex.edges_in:\n",
    "                edge.input_channel = edge.from_vertex.input_channel\n",
    "                edge.output_channel = int(edge.input_channel * edge.depth_factor)\n",
    "                vertex.input_channel += edge.output_channel\n",
    "\n",
    "                f_ver = self.vertices.index(edge.from_vertex)\n",
    "                print(', {}.{}_{}'.format(f_ver, edge.type[0], edge.output_channel), end=' ')\n",
    "            print()\n",
    "\n",
    "    def mutate_layer_size(self, v_list=[], s_list=[]):\n",
    "        for i in range(len(v_list)):\n",
    "            self.vertices[v_list[i]].outputs_mutable = s_list[i]\n",
    "\n",
    "    def add_vertex(self, after_vertex_id, vertex_type='linear', edge_type='identity'):\n",
    "        '''\n",
    "        3.0: 所有 vertex 和 edg 中记录的都是引用\n",
    "        '''\n",
    "        changed_edge = None\n",
    "        # 先寻找那条应该被移除的边, 将其删除\n",
    "        for i in self.vertices[after_vertex_id - 1].edges_out:\n",
    "            if i.to_vertex == self.vertices[after_vertex_id]:\n",
    "                self.vertices[after_vertex_id - 1].edges_out.remove(i)\n",
    "                break\n",
    "        for i in self.vertices[after_vertex_id].edges_in:\n",
    "            if i.from_vertex == self.vertices[after_vertex_id - 1]:\n",
    "                self.vertices[after_vertex_id].edges_in.remove(i)\n",
    "                break\n",
    "        for i, edge in enumerate(self.edges):\n",
    "            if edge.from_vertex == self.vertices[\n",
    "                    after_vertex_id - 1] and edge.to_vertex == self.vertices[after_vertex_id]:\n",
    "                changed_edge = self.edges[i]\n",
    "\n",
    "        # 创建新的 vertex, 并加入队列\n",
    "        vertex_add = Vertex(edges_in=set(), edges_out=set(), type=vertex_type)\n",
    "        self.vertices.insert(after_vertex_id, vertex_add)\n",
    "\n",
    "        # 创建新的 edge, 并加入队列\n",
    "        if edge_type == 'conv':\n",
    "            depth_f = random.random() * 2\n",
    "            filter_h = 1\n",
    "            filter_w = 1\n",
    "            edge_add1 = Edge(from_vertex=self.vertices[after_vertex_id - 1],\n",
    "                             to_vertex=self.vertices[after_vertex_id],\n",
    "                             type='conv',\n",
    "                             depth_factor=depth_f,\n",
    "                             filter_half_height=filter_h,\n",
    "                             filter_half_width=filter_w,\n",
    "                             stride_scale=0)\n",
    "        else:\n",
    "            edge_add1 = Edge(from_vertex=self.vertices[after_vertex_id - 1],\n",
    "                             to_vertex=self.vertices[after_vertex_id],\n",
    "                             type='identity')\n",
    "        # 取代的那条边后移\n",
    "        changed_edge.from_vertex = self.vertices[after_vertex_id]\n",
    "        # edge_add2 = Edge(from_vertex=self.vertices[after_vertex_id],to_vertex=self.vertices[after_vertex_id + 1])\n",
    "        self.edges.append(edge_add1)\n",
    "        # self.edges.append(edge_add2)\n",
    "\n",
    "        self.vertices[after_vertex_id - 1].edges_out.add(edge_add1)\n",
    "        vertex_add.edges_in.add(edge_add1), vertex_add.edges_out.add(changed_edge)\n",
    "        self.vertices[after_vertex_id + 1].edges_in.add(changed_edge)\n",
    "\n",
    "    def has_edge(self, from_vertex_id, to_vertex_id):\n",
    "        vertex_before = self.vertices[from_vertex_id]\n",
    "        vertex_after = self.vertices[to_vertex_id]\n",
    "        for edg in self.edges:\n",
    "            if edg.from_vertex == vertex_before and edg.to_vertex == vertex_after:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Vertex(object):\n",
    "    '''\n",
    "    edges_in, edges_out, HasField(bn_relu/linear), \n",
    "    inputs_mutable, outputs_mutable, properties_mutable\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 edges_in,\n",
    "                 edges_out,\n",
    "                 type='linear',\n",
    "                 inputs_mutable=1,\n",
    "                 outputs_mutable=1,\n",
    "                 properties_mutable=1):\n",
    "        '''\n",
    "        edges_in / edges_out : 使用set \n",
    "        each vertex can be inlear / 1*relu + 1*bn\n",
    "        '''\n",
    "        self.edges_in = edges_in\n",
    "        self.edges_out = edges_out\n",
    "        self.type = type  # ['linear' / 'bn_relu']\n",
    "\n",
    "        self.inputs_mutable = inputs_mutable\n",
    "        self.outputs_mutable = outputs_mutable\n",
    "        self.properties_mutable = properties_mutable\n",
    "\n",
    "        self.input_channel = 0\n",
    "        # Each vertex represents a 2ˆs x 2ˆs x d block of nodes. s and d are positive\n",
    "        # integers computed dynamically from the in-edges. s stands for \"scale\" so\n",
    "        # that 2ˆx x 2ˆs is the spatial size of the activations. d stands for \"depth\",\n",
    "        # the number of channels.\n",
    "\n",
    "\n",
    "class Edge(object):\n",
    "    '''\n",
    "    No Need:type, depth_factor, filter_half_width, filter_half_height, \n",
    "            stride_scale, depth_precedence, scale_precedence\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 from_vertex,\n",
    "                 to_vertex,\n",
    "                 type='identity',\n",
    "                 depth_factor=1,\n",
    "                 filter_half_width=None,\n",
    "                 filter_half_height=None,\n",
    "                 stride_scale=0):\n",
    "        self.from_vertex = from_vertex  # Source vertex ID.\n",
    "        self.to_vertex = to_vertex  # Destination vertex ID.\n",
    "        self.type = type\n",
    "\n",
    "        # In this case, the edge represents a convolution.\n",
    "        # 控制 channel 大小, this.channel = last channel * depth_factor\n",
    "        self.depth_factor = depth_factor\n",
    "        # Controls the strides(步幅) of the convolution. It will be 2ˆstride_scale. WHY ?????\n",
    "        self.stride_scale = stride_scale\n",
    "\n",
    "        if type == 'conv':\n",
    "            # 卷积核 size\n",
    "            # filter_width = 2 * filter_half_width + 1.\n",
    "            self.filter_half_width = filter_half_width\n",
    "            self.filter_half_height = filter_half_height\n",
    "            # 定义卷积步长, 卷积步长必须是 2 的幂次方？\n",
    "\n",
    "        # determine the inputs takes precedence in deciding the resolved depth or scale.\n",
    "        # self.depth_precedence = edge_proto.depth_precedence\n",
    "        # self.scale_precedence = edge_proto.scale_precedence\n",
    "\n",
    "        self.input_channel = 0\n",
    "        self.output_channel = 0\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, DNA):\n",
    "        super(Model, self).__init__()\n",
    "        self.dna = DNA\n",
    "        self.layer_vertex = torch.nn.ModuleList()\n",
    "        for vertex in DNA.vertices:\n",
    "            # 默认第一层和最后一层 vertex 非 hidden 层\n",
    "            if vertex.type == 'bn_relu':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(torch.nn.BatchNorm2d(vertex.input_channel),\n",
    "                                        torch.nn.ReLU(inplace=True)))\n",
    "            elif vertex.type == 'Global Pooling':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(\n",
    "                        # torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                        torch.nn.Linear(vertex.input_channel, DNA.output_size_channel)))\n",
    "            else:\n",
    "                self.layer_vertex.append(None)\n",
    "\n",
    "        self.layer_edge = torch.nn.ModuleList()\n",
    "        for edge in DNA.edges:\n",
    "            # TODO: 默认padding补全\n",
    "            if edge.type == 'conv':\n",
    "                self.layer_edge.append(\n",
    "                    torch.nn.Conv2d(edge.input_channel,\n",
    "                                    edge.output_channel,\n",
    "                                    kernel_size=(edge.filter_half_height * 2 + 1,\n",
    "                                                 edge.filter_half_width * 2 + 1),\n",
    "                                    stride=pow(2, edge.stride_scale),\n",
    "                                    padding=(edge.filter_half_height, edge.filter_half_width)))\n",
    "            else:\n",
    "                self.layer_edge.append(None)\n",
    "        self.batch_size = Evolution_pop.BATCH_SIZE\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        配置每层的 输入、输出、激活函数\n",
    "        '''\n",
    "        block_h = input.shape[0]\n",
    "        x = {\n",
    "            0: input,\n",
    "        }\n",
    "        for index, layer_vert in enumerate(self.layer_vertex[1:], start=1):\n",
    "            length = len(x)\n",
    "\n",
    "            a = torch.empty(block_h, 0, 0, 0)\n",
    "            for j, edg in enumerate(self.dna.vertices[index].edges_in):\n",
    "                ind_edg = self.dna.edges.index(edg)\n",
    "                ind_x = self.dna.vertices.index(edg.from_vertex)\n",
    "                t = x[ind_x]\n",
    "                if edg.type == 'conv':\n",
    "                    t = self.layer_edge[ind_edg](x[ind_x])\n",
    "                if j == 0:\n",
    "                    a = torch.empty(block_h, 0, t.shape[2], t.shape[3])\n",
    "                a = torch.cat((a, t), dim=1)\n",
    "\n",
    "            if self.dna.vertices[index].type == 'linear':\n",
    "                x[index] = a\n",
    "            elif self.dna.vertices[index].type == 'bn_relu':\n",
    "                x[index] = layer_vert(a)\n",
    "            elif self.dna.vertices[index].type == 'Global Pooling':\n",
    "                temp = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "                a = temp(a)\n",
    "                a = torch.squeeze(a, 3)\n",
    "                a = torch.squeeze(a, 2)\n",
    "                x[index] = layer_vert(a)\n",
    "\n",
    "        return x[len(x) - 1]\n",
    "\n",
    "\n",
    "class StructMutation():\n",
    "    '''\n",
    "    can mutate: hidden size, add edge, learning rate, add vertex, \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self._edge_types = []\n",
    "\n",
    "    def mutate(self, dna):\n",
    "        '''\n",
    "        TODO: 可能出现由于概率'没有任何变异'的情况，不能让其发生\n",
    "        1. 添加边时：添加identity, 则矩阵拼接时需要维度匹配 / 添加conv则需要是设置好参数\n",
    "        '''\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        mutated_cnt = 0\n",
    "        while mutated_cnt == 0:\n",
    "            # 1. Try the candidates in random order until one has the right connectivity.(Add)\n",
    "            for from_vertex_id, to_vertex_id in self._vertex_pair_candidates(dna):\n",
    "                if random.random() > 0.5:\n",
    "                    mutated_cnt += 1\n",
    "                    self._mutate_structure(mutated_dna, from_vertex_id, to_vertex_id)\n",
    "\n",
    "            # 2. Try to mutate learning Rate\n",
    "            self.mutate_learningRate(mutated_dna)\n",
    "\n",
    "            # 3. mutate the hidden layer's size\n",
    "            # self.mutate_hidden_size(dna)\n",
    "\n",
    "            # 4. Mutate the vertex (Add)\n",
    "            # self.mutate_vertex(mutated_dna)\n",
    "            if random.random() > 0.4:\n",
    "                mutated_cnt += 1\n",
    "                self.mutate_vertex(mutated_dna)\n",
    "        return mutated_dna\n",
    "\n",
    "    def _vertex_pair_candidates(self, dna):\n",
    "        \"\"\"Yields connectable vertex pairs.\"\"\"\n",
    "        from_vertex_ids = self._find_allowed_vertices(dna)\n",
    "        # if not from_vertex_ids: raise exceptions.MutationException(), 打乱次序\n",
    "        random.shuffle(from_vertex_ids)\n",
    "\n",
    "        to_vertex_ids = self._find_allowed_vertices(dna)\n",
    "        # if not to_vertex_ids: raise exceptions.MutationException()\n",
    "        random.shuffle(to_vertex_ids)\n",
    "\n",
    "        for to_vertex_id in to_vertex_ids:\n",
    "            # Avoid back-connections. TODO: 此处可能会涉及到 拓扑图的顺序判断\n",
    "            # disallowed_from_vertex_ids, _ = topology.propagated_set(to_vertex_id)\n",
    "            disallowed_from_vertex_ids = self._find_disallowed_from_vertices(dna, to_vertex_id)\n",
    "            for from_vertex_id in from_vertex_ids:\n",
    "                if from_vertex_id in disallowed_from_vertex_ids:\n",
    "                    continue\n",
    "                # This pair does not generate a cycle, so we yield it.\n",
    "                yield from_vertex_id, to_vertex_id\n",
    "\n",
    "    def _find_allowed_vertices(self, dna):\n",
    "        ''' TODO: 除第一层(假节点)外的所有vertex_id '''\n",
    "        return list(range(0, len(dna.vertices)))\n",
    "\n",
    "    def _find_disallowed_from_vertices(self, dna, to_vertex_id):\n",
    "        ''' 寻找不可作为起始层索引的：反向链接的，重复连接的Edge '''\n",
    "        res = list(range(to_vertex_id, len(dna.vertices)))\n",
    "        # 排查每个 vertex 是否不符合, 即索引在前面的 vertex 的所有 edges_out\n",
    "        for i, vertex in enumerate(dna.vertices[:to_vertex_id]):\n",
    "            for edge in vertex.edges_out:\n",
    "                if dna.vertices.index(edge.to_vertex) == to_vertex_id:\n",
    "                    if i not in res:\n",
    "                        res.append(i)\n",
    "                        continue\n",
    "        return res\n",
    "\n",
    "    def _mutate_structure(self, dna, from_vertex_id, to_vertex_id):\n",
    "        \"\"\"Adds the edge to the DNA instance.\"\"\"\n",
    "        if dna.has_edge(from_vertex_id, to_vertex_id):\n",
    "            return False\n",
    "        else:\n",
    "            # TODO: edge 有两个类型，identity 和 conv (主要调节 stride, 在默认padding补全的情况下)\n",
    "            # 1. 若数据维度不变，可以用identity， 则需要检查 stride 是否不变\n",
    "            res = True\n",
    "            bin_stride = 0\n",
    "            for vertex_id, vert in enumerate(dna.vertices[from_vertex_id + 1:to_vertex_id],\n",
    "                                             start=from_vertex_id + 1):\n",
    "                edg_direct = None\n",
    "                for edg in vert.edges_in:\n",
    "                    if edg.from_vertex == dna.vertices[\n",
    "                            vertex_id - 1] and edg.to_vertex == dna.vertices[vertex_id]:\n",
    "                        edg_direct = edg\n",
    "                        break\n",
    "                if edg_direct.stride_scale != 0:\n",
    "                    res = False\n",
    "                    bin_stride += edg_direct.stride_scale\n",
    "            if res and random.random()>0.6:\n",
    "                print(\"[add_edge]->identity:\", from_vertex_id, to_vertex_id)\n",
    "                new_edge = dna.add_edge(from_vertex_id, to_vertex_id)\n",
    "                return res\n",
    "            # 2. 若数据维度改变(变小)，要用conv\n",
    "            print(\"[add_edge]->conv:\", from_vertex_id, to_vertex_id)\n",
    "            depth_f = random.random() * 2\n",
    "            filter_h = 1\n",
    "            filter_w = 1\n",
    "            new_edge = dna.add_edge(from_vertex_id,\n",
    "                                    to_vertex_id,\n",
    "                                    edge_type='conv',\n",
    "                                    depth_factor=depth_f,\n",
    "                                    filter_half_height=filter_h,\n",
    "                                    filter_half_width=filter_w,\n",
    "                                    stride_scale=bin_stride)\n",
    "            return True\n",
    "\n",
    "    def mutate_hidden_size(self, dna):\n",
    "        '''\n",
    "        TODO: mutate the hidden layer's size \n",
    "        高斯分布随机生成, 对所有 hidden layer 变动...不可取\n",
    "        '''\n",
    "        # for i in list(range(1, len(dna.vertices) - 1)):\n",
    "        #     if random.random() > 0.6:\n",
    "        #         last = dna.vertices[i].outputs_mutable\n",
    "        #         before = dna.vertices[i - 1].outputs_mutable\n",
    "        #         after = dna.vertices[i + 1].outputs_mutable\n",
    "\n",
    "        #         alpha = min(before - last, last - after) / 3\n",
    "        #         next = last + alpha * np.random.randn(1)\n",
    "        #         next = int(next[0])\n",
    "        #         if next > before:\n",
    "        #             next = before\n",
    "        #         elif next < after:\n",
    "        #             next = after\n",
    "        #         dna.vertices[i].outputs_mutable = next\n",
    "\n",
    "    def mutate_learningRate(self, dna):\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        # Mutate the learning rate by a random factor between 0.5 and 2.0,\n",
    "        # uniformly distributed in log scale.\n",
    "        factor = 2**random.uniform(-1.0, 1.0)\n",
    "        mutated_dna.learning_rate = dna.learning_rate * factor\n",
    "        return mutated_dna\n",
    "\n",
    "    def mutate_vertex(self, dna):\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        # 随机选择一个 vertex_id 插入 vertex\n",
    "        after_vertex_id = random.choice(self._find_allowed_vertices(dna))\n",
    "        if after_vertex_id == 0:\n",
    "            return mutated_dna\n",
    "\n",
    "        print('outputs_mutable', dna.vertices[after_vertex_id].outputs_mutable,\n",
    "              dna.vertices[after_vertex_id - 1].outputs_mutable)\n",
    "        # TODO: how it supposed to mutate\n",
    "        vertex_type = 'linear'\n",
    "        if random.random() > 0.2:\n",
    "            vertex_type = 'bn_relu'\n",
    "\n",
    "        edge_type = 'identity'\n",
    "        if random.random() > 0.2:\n",
    "            edge_type = 'conv'\n",
    "\n",
    "        mutated_dna.add_vertex(after_vertex_id, vertex_type, edge_type)\n",
    "        return mutated_dna\n",
    "\n",
    "\n",
    "class Evolution_pop:\n",
    "    _population_size_setpoint = 6\n",
    "    _max_layer_size = 5\n",
    "    _evolve_time = 100\n",
    "    fitness_pool = []\n",
    "\n",
    "    EPOCH = 2  # 训练整批数据多少次\n",
    "    BATCH_SIZE = 50\n",
    "    N_CLASSES = 10\n",
    "\n",
    "    # LR = 0.001          # 学习率\n",
    "\n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        初始化DNA: 一层hidden(节点数不同); 都为linear\n",
    "        接收传入的训练数据 data\n",
    "        初始化 Mutation 类\n",
    "        '''\n",
    "        self.population = []\n",
    "        for i in range(self._population_size_setpoint):\n",
    "            dna_iter = DNA()\n",
    "            self.population.append(dna_iter)\n",
    "        self.data = data\n",
    "        self.struct_mutation = StructMutation()\n",
    "\n",
    "    def decode(self):\n",
    "        '''\n",
    "         对当前population队列中的每个未训练过的个体进行训练 \n",
    "         https://www.cnblogs.com/denny402/p/7520063.html\n",
    "        '''\n",
    "        for dna in self.population:\n",
    "            if dna.fitness != -1.0:\n",
    "                continue\n",
    "            # TODO: 新训练的个体将fitness加入fitness_pool\n",
    "            dna.calculate_flow()\n",
    "            net = Model(dna)\n",
    "            print(\"[decode].[\", dna.dna_cnt, \"]\", net)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=dna.learning_rate)\n",
    "            # the target label is not one-hotted\n",
    "            loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_loader, testloader = self.data.getData()\n",
    "\n",
    "            # print(\"[Evolution_pop].[decode]->test_x: \", test_x.shape)\n",
    "            accuracy = 0\n",
    "            # training and testing\n",
    "            for epoch in range(self.EPOCH):\n",
    "                step = 0\n",
    "                # TODO: 用movan的enumerate会报错，why?\n",
    "                max_tep = int(60000 / train_loader.batch_size)\n",
    "\n",
    "                train_acc = .0\n",
    "                len_y = 0\n",
    "                for step, (b_x, b_y) in enumerate(train_loader):\n",
    "                    # print(\"[b_x, b_y].shape: \", b_x.shape, b_y.shape)\n",
    "                    # 分配 batch data, normalize x when iterate train_loader\n",
    "                    output = net(b_x)  # cnn output\n",
    "                    idy = b_y.view(-1, 1)\n",
    "                    # b_y = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, idy, 1).long()\n",
    "\n",
    "                    loss = loss_func(output, b_y)  # cross entropy loss\n",
    "                    # clear gradients for this training step\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()  # backpropagation, compute gradients\n",
    "                    optimizer.step()  # apply gradients\n",
    "\n",
    "                    # target = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, idy, 1).long()\n",
    "                    # train_correct = (output == target).sum()\n",
    "                    # train_acc += train_correct.data[0]\n",
    "                    # len_y += len(target)\n",
    "\n",
    "                    if step % 50 == 0:\n",
    "                        pred = net(b_x)\n",
    "\n",
    "                        # pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "                        # accuracy = float(\n",
    "                        #     (pred_y == test_y.data.numpy()).astype(int).sum()) / float(\n",
    "                        #         test_y.size(0))\n",
    "\n",
    "                        # accuracy = self.Accuracy(net, testloader)\n",
    "                        # print('Epoch: ', epoch, 'step: ', step,'| train loss: %.4f' % loss.data.numpy(),'| test accuracy: %.2f' % accuracy)\n",
    "                        print(\"\\r\" + 'Epoch: ' + str(epoch) + ' step: ' + str(step) + '[' +\n",
    "                              \">>>\" * int(step / 50) + ']',\n",
    "                              end=' ')\n",
    "                        # print('loss: %.4f' % loss.data.numpy(), '| accuracy: %.4f' % accuracy, end=' ')\n",
    "                        print('loss: %.4f' % loss.data.numpy(), end=' ')\n",
    "                print('')\n",
    "\n",
    "            # evaluation--------------------------------\n",
    "\n",
    "            # net.eval()\n",
    "            # eval_loss = 0.\n",
    "            # eval_acc = 0.\n",
    "\n",
    "            # len_y = 0\n",
    "            # for batch_x, batch_y in testloader:\n",
    "            #     batch_x, batch_y = Variable(batch_x, volatile=True), Variable(batch_y,\n",
    "            #                                                                   volatile=True)\n",
    "            #     out = net(batch_x)\n",
    "            #     # b_y = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, b_y, 1)\n",
    "\n",
    "            #     loss = loss_func(out, batch_y)\n",
    "            #     eval_loss += loss.data[0]\n",
    "            #     pred = torch.max(out, 1)[1]\n",
    "\n",
    "            #     target = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, batch_y, 1).long()\n",
    "            #     num_correct = (pred == target).sum()\n",
    "            #     eval_acc += num_correct.data[0]\n",
    "\n",
    "            #     len_y += len(target)\n",
    "            # print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / len_y, eval_acc / len_y))\n",
    "\n",
    "            accuracy = self.Accuracy(net, testloader)\n",
    "            print('----- Accuracy: {:.6f} -----'.format(accuracy))\n",
    "            # dna.fitness = eval_acc / len_y\n",
    "            dna.fitness = accuracy\n",
    "            print('')\n",
    "\n",
    "    def Accuracy(self, net, testloader):\n",
    "        ''' https://blog.csdn.net/Arctic_Beacon/article/details/85068188 '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "        class_correct = list(0. for i in range(self.N_CLASSES))\n",
    "        class_total = list(0. for i in range(self.N_CLASSES))\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == labels).squeeze()\n",
    "                for i in range(self.BATCH_SIZE):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        # for i in range(self.N_CLASSES):\n",
    "        #     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        return sum(class_correct) / sum(class_total)\n",
    "\n",
    "    def choose_varition_dna(self):\n",
    "        '''\n",
    "        每次挑选两个体,取fitness,判断要kill还是reproduce\n",
    "        '''\n",
    "        while self._evolve_time > 0:\n",
    "            self._evolve_time -= 1\n",
    "            self.decode()\n",
    "            # 每次挑两个个体并提取出训练成绩fitness\n",
    "            individual_pair = random.sample(list(enumerate(self.population)), 2)\n",
    "            # TODO: 话说他这样取出来如果删掉的话真的能保证吗\n",
    "            individual_pair.sort(key=lambda i: i[1].fitness, reverse=True)\n",
    "            # better_individual = individual_pair[0]\n",
    "            # worse_individual = individual_pair[1]\n",
    "            # print(\"Choice: \",self._evolve_time,end=' ')\n",
    "            # print(\"better: \",better_individual[0],'->',better_individual[1].fitness, end=' ')\n",
    "            # print(\"worse: \", worse_individual[0],'->', worse_individual[1].fitness, end=' ')\n",
    "            better_individual = individual_pair[0][0]\n",
    "            worse_individual = individual_pair[1][0]\n",
    "            individual_pair = []\n",
    "            # (population过大->kill不好的)，反之(population过小->reproduce好的)\n",
    "            if len(self.population) >= self._population_size_setpoint:\n",
    "                print(\"--kill worse\", worse_individual)\n",
    "                self._kill_individual(worse_individual)\n",
    "            elif len(self.population) < self._population_size_setpoint:\n",
    "                print(\"--reproduce better\", better_individual)\n",
    "                self._reproduce_and_train_individual(better_individual)\n",
    "\n",
    "    def _kill_individual(self, index):\n",
    "        ''' kill by the index of population '''\n",
    "        # self._print_population()\n",
    "\n",
    "        del self.population[index]\n",
    "        # debug\n",
    "        self._print_population()\n",
    "\n",
    "    def _reproduce_and_train_individual(self, index):\n",
    "        ''' \n",
    "        inherit the parent, mutate, join the population \n",
    "        为了节省时间实际上有 Weight Inheritance\n",
    "        '''\n",
    "        # self._print_population()\n",
    "\n",
    "        # inherit the parent (attention the dna_cnt)\n",
    "        son = self.inherit_DNA(self.population[index])\n",
    "\n",
    "        self.struct_mutation.mutate(son)\n",
    "        self.population.append(son)\n",
    "        # debug\n",
    "        self._print_population()\n",
    "\n",
    "    def inherit_DNA(self, dna):\n",
    "        ''' inderit from parent: reset dna_cnt, fitness '''\n",
    "        son = copy.deepcopy(dna)\n",
    "        global DNA_cnt\n",
    "        son.dna_cnt = DNA_cnt\n",
    "        DNA_cnt += 1\n",
    "        son.fitness = -1\n",
    "        return son\n",
    "\n",
    "    def _print_population(self):\n",
    "        print(\"pop sum: \", len(self.population), '|', end=' ')\n",
    "        index = 0\n",
    "        for i in self.population:\n",
    "            print('(', index, '->', i.dna_cnt, ')', end=' ')\n",
    "            index += 1\n",
    "        print('')\n",
    "\n",
    "\n",
    "class MadeDate:\n",
    "    DOWNLOAD_MNIST = False  # 如果你已经下载好了mnist数据就写上 False\n",
    "    DOWNLOAD_FSAHION_MNIST = False\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    def __init__(self):\n",
    "        # Mnist digits dataset\n",
    "        '''\n",
    "        if not (os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "            # not mnist dir or mnist is empyt dir\n",
    "            self.DOWNLOAD_MNIST = True\n",
    "        if not (os.path.exists('./FashionMNIST/')) or not os.listdir('./FashionMNIST/'):\n",
    "            # not mnist dir or mnist is empyt dir\n",
    "            self.DOWNLOAD_FSAHION_MNIST = True\n",
    "        '''\n",
    "\n",
    "    def CIFR10(self):\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        # 定义了我们的训练集，名字就叫trainset，至于后面这一堆，其实就是一个类：\n",
    "        # torchvision.datasets.CIFAR10( )也是封装好了的，就在我前面提到的torchvision.datasets\n",
    "        # 模块中,不必深究，如果想深究就看我这段代码后面贴的图1，其实就是在下载数据\n",
    "        #（不翻墙可能会慢一点吧）然后进行变换，可以看到transform就是我们上面定义的transform\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./dataset',\n",
    "                                                train=True,\n",
    "                                                download=False,\n",
    "                                                transform=transform)\n",
    "        # trainloader其实是一个比较重要的东西，我们后面就是通过trainloader把数据传入网\n",
    "        # 络，当然这里的trainloader其实是个变量名，可以随便取，重点是他是由后面的\n",
    "        # torch.utils.data.DataLoader()定义的，这个东西来源于torch.utils.data模块，\n",
    "        #  网页链接http://pytorch.org/docs/0.3.0/data.html，这个类可见我后面图2\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                       batch_size=self.BATCH_SIZE,\n",
    "                                                       shuffle=True,\n",
    "                                                       num_workers=2)\n",
    "        # 对于测试集的操作和训练集一样，我就不赘述了\n",
    "        testset = torchvision.datasets.CIFAR10(root='./dataset',\n",
    "                                               train=False,\n",
    "                                               download=False,\n",
    "                                               transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                      batch_size=2000,\n",
    "                                                      shuffle=False,\n",
    "                                                      num_workers=2)\n",
    "\n",
    "        # 设置DNA的size\n",
    "        DNA.input_size_height = 32\n",
    "        DNA.input_size_width = 32\n",
    "        DNA.input_size_channel = 3\n",
    "        DNA.output_size_height = 1\n",
    "        DNA.output_size_width = 1\n",
    "        DNA.output_size_channel = 10\n",
    "        return self.trainloader, self.testloader\n",
    "\n",
    "    def getData(self):\n",
    "        return self.trainloader, self.testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 0 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0581  loss: 2.2423  loss: 2.1669  loss: 2.1825  loss: 2.0981  loss: 2.0158  loss: 2.0433  loss: 2.0657  loss: 1.9882  loss: 1.9743  loss: 2.3199  loss: 2.0508  loss: 2.0711  loss: 2.1635  loss: 2.0279  loss: 2.0181 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1677  loss: 1.9855  loss: 2.1611  loss: 2.0334  loss: 2.2012  loss: 1.9241  loss: 2.0451  loss: 1.9493  loss: 2.0167  loss: 2.1071  loss: 2.0371  loss: 2.2272  loss: 2.0259  loss: 2.0673  loss: 2.0327  loss: 2.0691 \n",
      "----- Accuracy: 0.272000 -----\n",
      "\n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 1 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2855  loss: 2.0473  loss: 2.0651  loss: 2.1011  loss: 2.1073  loss: 2.1732  loss: 2.0986  loss: 2.0017  loss: 2.0005  loss: 2.0529  loss: 2.0106  loss: 2.0427  loss: 2.0418  loss: 2.1436  loss: 2.0560  loss: 2.0032 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0690  loss: 2.0962  loss: 2.0083  loss: 2.0758  loss: 2.2638  loss: 2.0970  loss: 2.1291  loss: 2.0047  loss: 1.9978  loss: 1.9262  loss: 1.9878  loss: 1.8988  loss: 2.1214  loss: 1.9548  loss: 2.0618  loss: 2.0111 \n",
      "----- Accuracy: 0.228000 -----\n",
      "\n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 2 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9880  loss: 2.1021  loss: 2.1278  loss: 2.0402  loss: 2.1406  loss: 2.1267  loss: 1.9482  loss: 2.0863  loss: 2.1209  loss: 2.0679  loss: 2.0566  loss: 2.1511  loss: 2.0139  loss: 2.0444  loss: 2.0858  loss: 2.0879 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0792  loss: 2.1013  loss: 2.0884  loss: 1.9913  loss: 2.0405  loss: 2.1231  loss: 2.0111  loss: 2.1824  loss: 1.9340  loss: 2.1062  loss: 2.1305  loss: 2.1185  loss: 1.8488  loss: 2.3126  loss: 2.1050  loss: 1.9708 \n",
      "----- Accuracy: 0.220000 -----\n",
      "\n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 3 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0570  loss: 2.0627  loss: 2.0612  loss: 2.0822  loss: 2.2801  loss: 2.1058  loss: 2.0691  loss: 2.2676  loss: 2.0864  loss: 2.1287  loss: 2.0211  loss: 2.1025  loss: 2.0287  loss: 2.0289  loss: 1.9985  loss: 2.1491 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9527  loss: 2.1966  loss: 2.0720  loss: 1.9854  loss: 2.1946  loss: 2.1593  loss: 2.0641  loss: 1.9874  loss: 2.0391  loss: 2.1552  loss: 1.9952  loss: 2.1568  loss: 2.0900  loss: 2.2200  loss: 2.0678  loss: 2.2745 \n",
      "----- Accuracy: 0.272000 -----\n",
      "\n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 4 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1519  loss: 2.2058  loss: 2.0857  loss: 2.1498  loss: 2.1666  loss: 1.9614  loss: 2.0617  loss: 2.2118  loss: 1.8772  loss: 2.0051  loss: 2.0602  loss: 1.9768  loss: 1.9689  loss: 2.1055  loss: 2.1345  loss: 2.1216 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0406  loss: 2.1887  loss: 1.9634  loss: 2.0952  loss: 2.0463  loss: 2.2493  loss: 2.2122  loss: 1.9576  loss: 2.0445  loss: 2.1630  loss: 2.1806  loss: 2.2319  loss: 2.0694  loss: 2.0382  loss: 2.1213  loss: 1.9329 \n",
      "----- Accuracy: 0.264000 -----\n",
      "\n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 5 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1448  loss: 2.2246  loss: 2.1476  loss: 2.0875  loss: 2.0127  loss: 2.1304  loss: 2.1544  loss: 2.1360  loss: 2.1669  loss: 2.0959  loss: 2.0543  loss: 2.0302  loss: 1.9705  loss: 2.1340  loss: 2.0464  loss: 2.0243 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9654  loss: 2.1811  loss: 1.9289  loss: 2.3547  loss: 2.1185  loss: 2.1043  loss: 2.1846  loss: 2.0307  loss: 1.9676  loss: 2.0853  loss: 2.1757  loss: 1.9647  loss: 2.0054  loss: 2.1516  loss: 2.1869  loss: 2.1815 \n",
      "----- Accuracy: 0.252000 -----\n",
      "\n",
      "--kill worse 5\n",
      "DNA [ 5 ]销毁->fitness 0.252\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 1 ) ( 2 -> 2 ) ( 3 -> 3 ) ( 4 -> 4 ) \n",
      "--reproduce better 4\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 1 ) ( 2 -> 2 ) ( 3 -> 3 ) ( 4 -> 4 ) ( 5 -> 6 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "[decode].[ 6 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9529  loss: 2.1780  loss: 2.1167  loss: 2.0580  loss: 2.1001  loss: 2.1533  loss: 2.1814  loss: 2.2456  loss: 2.0634  loss: 1.8805  loss: 2.0791  loss: 2.0015  loss: 2.0577  loss: 1.9681  loss: 2.1323  loss: 2.0319 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2109  loss: 2.0466  loss: 1.8047  loss: 2.3921  loss: 2.0822  loss: 2.1796  loss: 2.0395  loss: 2.0916  loss: 2.0450  loss: 1.9792  loss: 2.1435  loss: 1.9851  loss: 2.0471  loss: 2.0083  loss: 2.0778  loss: 2.0266 \n",
      "----- Accuracy: 0.248000 -----\n",
      "\n",
      "--kill worse 5\n",
      "DNA [ 6 ]销毁->fitness 0.248\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 1 ) ( 2 -> 2 ) ( 3 -> 3 ) ( 4 -> 4 ) \n",
      "--reproduce better 1\n",
      "[add_edge]->conv: 0 2\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 1 ) ( 2 -> 2 ) ( 3 -> 3 ) ( 4 -> 4 ) ( 5 -> 7 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 , 0.c_1 \n",
      "[decode].[ 7 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9512  loss: 2.0681  loss: 2.0478  loss: 2.1564  loss: 2.1290  loss: 2.0945  loss: 1.9624  loss: 2.2318  loss: 2.0157  loss: 2.1772  loss: 1.9948  loss: 2.0568  loss: 1.9799  loss: 2.0895  loss: 2.1267  loss: 2.0099 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9783  loss: 2.0207  loss: 2.0182  loss: 2.1382  loss: 2.0405  loss: 1.9506  loss: 2.2009  loss: 1.8319  loss: 1.9107  loss: 1.9988  loss: 1.8631  loss: 1.9011  loss: 1.8186  loss: 1.9523  loss: 2.0443  loss: 2.0527 \n",
      "----- Accuracy: 0.248000 -----\n",
      "\n",
      "--kill worse 1\n",
      "DNA [ 1 ]销毁->fitness 0.228\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 4 ) ( 4 -> 7 ) \n",
      "--reproduce better 3\n",
      "[add_edge]->conv: 0 2\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 4 ) ( 4 -> 7 ) ( 5 -> 8 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 , 0.c_3 \n",
      "[decode].[ 8 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9920  loss: 1.9782  loss: 2.0576  loss: 2.1088  loss: 2.0266  loss: 2.1062  loss: 2.1504  loss: 2.1205  loss: 2.0407  loss: 1.9949  loss: 2.0023  loss: 2.2004  loss: 2.0947  loss: 2.0592  loss: 2.0132  loss: 2.1565 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0590  loss: 2.0236  loss: 2.0452  loss: 2.1652  loss: 1.9884  loss: 2.1323  loss: 2.0206  loss: 2.0378  loss: 2.0716  loss: 1.9364  loss: 2.3217  loss: 2.1461  loss: 2.0754  loss: 1.8598  loss: 2.1049  loss: 2.0655 \n",
      "----- Accuracy: 0.296000 -----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 7 ]销毁->fitness 0.248\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 4 ) ( 4 -> 8 ) \n",
      "--reproduce better 4\n",
      "outputs_mutable 0 0\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 4 ) ( 4 -> 8 ) ( 5 -> 9 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_2 \n",
      "vertex [ 3 ].0 , 2.i_2 , 0.c_3 \n",
      "[decode].[ 9 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1181  loss: 1.9592  loss: 1.9213  loss: 1.8968  loss: 2.1047  loss: 2.1394  loss: 2.1900  loss: 1.8041  loss: 1.7754  loss: 1.8403  loss: 1.9017  loss: 1.8792  loss: 1.8630  loss: 1.9908  loss: 1.8496  loss: 1.9997 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.8067  loss: 1.8982  loss: 1.9668  loss: 1.7219  loss: 1.8420  loss: 2.0323  loss: 1.8908  loss: 1.9016  loss: 1.6513  loss: 2.0602  loss: 1.8451  loss: 1.9595  loss: 2.0280  loss: 1.7395  loss: 1.9722  loss: 1.7078 \n",
      "----- Accuracy: 0.336000 -----\n",
      "\n",
      "--kill worse 3\n",
      "DNA [ 4 ]销毁->fitness 0.264\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 8 ) ( 4 -> 9 ) \n",
      "--reproduce better 4\n",
      "[add_edge]->conv: 1 3\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 3 ) ( 3 -> 8 ) ( 4 -> 9 ) ( 5 -> 10 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_2 \n",
      "vertex [ 3 ].0 , 2.i_2 , 1.c_2 , 0.c_3 \n",
      "[decode].[ 10 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=7, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9511  loss: 2.2858  loss: 2.1003  loss: 2.2616  loss: 2.4291  loss: 2.1154  loss: 2.1275  loss: 1.8477  loss: 2.4981  loss: 2.2075  loss: 2.0660  loss: 2.2066  loss: 2.0563  loss: 2.0079  loss: 2.0840  loss: 2.0947 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0862  loss: 2.1865  loss: 1.9612  loss: 1.9090  loss: 2.1685  loss: 1.9712  loss: 1.9522  loss: 1.9418  loss: 2.2530  loss: 2.0474  loss: 2.0616  loss: 2.1573  loss: 2.1554  loss: 2.0386  loss: 1.8793  loss: 2.1762 \n",
      "----- Accuracy: 0.248000 -----\n",
      "\n",
      "--kill worse 2\n",
      "DNA [ 3 ]销毁->fitness 0.272\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 9 ) ( 4 -> 10 ) \n",
      "--reproduce better 0\n",
      "[add_edge]->conv: 0 2\n",
      "outputs_mutable 0 0\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 9 ) ( 4 -> 10 ) ( 5 -> 11 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_4 \n",
      "vertex [ 3 ].0 , 0.c_5 , 2.i_4 \n",
      "[decode].[ 11 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=9, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9825  loss: 1.9936  loss: 1.7973  loss: 1.7738  loss: 1.7175  loss: 1.7663  loss: 1.8358  loss: 1.8975  loss: 1.7082  loss: 1.9110  loss: 1.9076  loss: 1.7614  loss: 1.6970  loss: 1.8402  loss: 1.7849  loss: 1.8578 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0778  loss: 1.9745  loss: 2.0018  loss: 1.9825  loss: 1.5582  loss: 1.6736  loss: 1.7628  loss: 1.7398  loss: 1.7451  loss: 1.7831  loss: 1.7868  loss: 1.6210  loss: 2.1232  loss: 1.8078  loss: 1.9111  loss: 1.7924 \n",
      "----- Accuracy: 0.344000 -----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 10 ]销毁->fitness 0.248\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 9 ) ( 4 -> 11 ) \n",
      "--reproduce better 4\n",
      "[add_edge]->identity: 0 2\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 9 ) ( 4 -> 11 ) ( 5 -> 12 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 0.i_3 , 1.c_4 \n",
      "vertex [ 3 ].0 , 2.i_7 , 0.c_5 \n",
      "[decode].[ 12 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9587  loss: 1.8297  loss: 1.9871  loss: 1.9049  loss: 1.8471  loss: 1.9972  loss: 1.8169  loss: 1.9666  loss: 1.8393  loss: 1.7395  loss: 1.8538  loss: 1.7150  loss: 1.7159  loss: 1.7128  loss: 1.8134  loss: 1.8671 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6785  loss: 2.0029  loss: 1.8248  loss: 1.7428  loss: 1.6765  loss: 1.6869  loss: 1.8644  loss: 1.9591  loss: 1.6861  loss: 1.9157  loss: 1.7610  loss: 1.7241  loss: 1.8505  loss: 1.7765  loss: 1.8186  loss: 1.8658 \n",
      "----- Accuracy: 0.380000 -----\n",
      "\n",
      "--kill worse 3\n",
      "DNA [ 9 ]销毁->fitness 0.336\n",
      "pop sum:  5 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 11 ) ( 4 -> 12 ) \n",
      "--reproduce better 0\n",
      "[add_edge]->conv: 0 2\n",
      "outputs_mutable 0 0\n",
      "pop sum:  6 | ( 0 -> 0 ) ( 1 -> 2 ) ( 2 -> 8 ) ( 3 -> 11 ) ( 4 -> 12 ) ( 5 -> 13 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 \n",
      "vertex [ 3 ].0 , 2.i_3 , 0.c_4 \n",
      "[decode].[ 13 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=7, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1217  loss: 2.2058  loss: 1.9924  loss: 2.1900  loss: 2.0661  loss: 1.9294  loss: 2.0754  loss: 2.1587  loss: 2.3865  loss: 1.9856  loss: 1.9896  loss: 2.2238  loss: 2.0337  loss: 2.1236  loss: 1.9674  loss: 1.7496 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.8482  loss: 2.0788  loss: 2.0119  loss: 2.0384  loss: 2.1478  loss: 2.1105  loss: 1.9525  loss: 2.1214  loss: 1.9145  loss: 2.0099  loss: 1.9250  loss: 2.0569  loss: 2.0805  loss: 2.1376  loss: 2.1249  loss: 2.1479 \n",
      "----- Accuracy: 0.276000 -----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 0 ]销毁->fitness 0.272\n",
      "pop sum:  5 | ( 0 -> 2 ) ( 1 -> 8 ) ( 2 -> 11 ) ( 3 -> 12 ) ( 4 -> 13 ) \n",
      "--reproduce better 1\n",
      "pop sum:  6 | ( 0 -> 2 ) ( 1 -> 8 ) ( 2 -> 11 ) ( 3 -> 12 ) ( 4 -> 13 ) ( 5 -> 14 ) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.i_3 , 0.c_3 \n",
      "[decode].[ 14 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2793  loss: 2.1944  loss: 2.0661  loss: 2.0781  loss: 2.1561  loss: 2.1376  loss: 1.9674  loss: 2.2920  loss: 2.3417  loss: 1.9543  loss: 2.0835  loss: 2.2109  loss: 2.0377  loss: 2.1787  loss: 1.9709  loss: 2.2332 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0077  loss: 2.0962  loss: 2.2651  loss: 2.1982  loss: 2.0646  loss: 1.8591  loss: 2.0601  loss: 1.9120  loss: 2.1440  loss: 2.0523  loss: 1.9178  loss: 1.9774  loss: 2.0011  loss: 2.0933  loss: 2.1018  loss: 2.0367 \n",
      "----- Accuracy: 0.248000 -----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 2 ]销毁->fitness 0.22\n",
      "pop sum:  5 | ( 0 -> 8 ) ( 1 -> 11 ) ( 2 -> 12 ) ( 3 -> 13 ) ( 4 -> 14 ) \n",
      "--reproduce better 0\n",
      "outputs_mutable 0 0\n",
      "pop sum:  6 | ( 0 -> 8 ) ( 1 -> 11 ) ( 2 -> 12 ) ( 3 -> 13 ) ( 4 -> 14 ) ( 5 -> 15 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_5 \n",
      "vertex [ 3 ].0 , 2.i_5 , 0.c_3 \n",
      "[decode].[ 15 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9569  loss: 2.0241  loss: 2.0413  loss: 1.8870  loss: 1.9723  loss: 1.9537  loss: 1.8673  loss: 1.8506  loss: 1.8344  loss: 1.9383  loss: 1.6767  loss: 1.7885  loss: 1.9323  loss: 1.7529  loss: 1.9154  loss: 1.7587 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.8859  loss: 1.7296  loss: 2.0617  loss: 1.8594  loss: 1.6991  loss: 1.6569  loss: 1.8793  loss: 1.9436  loss: 1.8760  loss: 1.8134  loss: 1.8697  loss: 1.7871  loss: 1.9782  loss: 2.1007  loss: 1.6919  loss: 1.7611 \n",
      "----- Accuracy: 0.372000 -----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 14 ]销毁->fitness 0.248\n",
      "pop sum:  5 | ( 0 -> 8 ) ( 1 -> 11 ) ( 2 -> 12 ) ( 3 -> 13 ) ( 4 -> 15 ) \n",
      "--reproduce better 2\n",
      "[add_edge]->conv: 1 3\n",
      "pop sum:  6 | ( 0 -> 8 ) ( 1 -> 11 ) ( 2 -> 12 ) ( 3 -> 13 ) ( 4 -> 15 ) ( 5 -> 16 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_4 , 0.i_3 \n",
      "vertex [ 3 ].0 , 0.c_5 , 1.c_4 , 2.i_7 \n",
      "[decode].[ 16 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9315  loss: 1.9742  loss: 1.9924  loss: 2.0101  loss: 2.0544  loss: 1.9754  loss: 1.8191  loss: 1.7899  loss: 2.0071  loss: 1.7542  loss: 2.1361  loss: 1.8344  loss: 1.6540  loss: 1.9647  loss: 1.8703  loss: 1.7950 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.5498  loss: 1.8417  loss: 1.8878  loss: 1.6117  loss: 1.7308  loss: 1.8129  loss: 1.6830  loss: 1.7042  loss: 1.8238  loss: 1.9130  loss: 1.7566  loss: 1.7076  loss: 1.6550  loss: 1.6409  loss: 1.7289  loss: 1.7205 \n",
      "----- Accuracy: 0.312000 -----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 8 ]销毁->fitness 0.296\n",
      "pop sum:  5 | ( 0 -> 11 ) ( 1 -> 12 ) ( 2 -> 13 ) ( 3 -> 15 ) ( 4 -> 16 ) \n",
      "--reproduce better 1\n",
      "[add_edge]->conv: 1 3\n",
      "pop sum:  6 | ( 0 -> 11 ) ( 1 -> 12 ) ( 2 -> 13 ) ( 3 -> 15 ) ( 4 -> 16 ) ( 5 -> 17 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_4 , 0.i_3 \n",
      "vertex [ 3 ].0 , 0.c_5 , 1.c_5 , 2.i_7 \n",
      "[decode].[ 17 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=17, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.2492  loss: 2.2233  loss: 2.1113  loss: 2.0495  loss: 2.1029  loss: 2.0369  loss: 1.7160  loss: 1.8872  loss: 1.9907  loss: 1.9732  loss: 1.6855  loss: 1.9668  loss: 2.0884  loss: 1.8592  loss: 1.7263  loss: 1.6889 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.7142  loss: 1.9810  loss: 1.7696  loss: 1.9812  loss: 1.8007  loss: 1.9523  loss: 1.6153  loss: 1.8287  loss: 1.8425  loss: 1.7882  loss: 1.7242  loss: 2.1378  loss: 2.0786  loss: 1.9384  loss: 2.0415  loss: 2.0802 \n",
      "----- Accuracy: 0.328000 -----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 16 ]销毁->fitness 0.312\n",
      "pop sum:  5 | ( 0 -> 11 ) ( 1 -> 12 ) ( 2 -> 13 ) ( 3 -> 15 ) ( 4 -> 17 ) \n",
      "--reproduce better 3\n",
      "[add_edge]->identity: 1 3\n",
      "pop sum:  6 | ( 0 -> 11 ) ( 1 -> 12 ) ( 2 -> 13 ) ( 3 -> 15 ) ( 4 -> 17 ) ( 5 -> 18 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_5 \n",
      "vertex [ 3 ].0 , 0.c_3 , 1.i_3 , 2.i_5 \n",
      "[decode].[ 18 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=11, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9983  loss: 2.0214  loss: 2.1041  loss: 2.0664  loss: 2.0241  loss: 1.8866  loss: 2.0833  loss: 2.0348  loss: 1.7082  loss: 1.7996  loss: 2.0321  loss: 1.9148  loss: 2.0813  loss: 1.7609  loss: 1.8783  loss: 1.8483 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.9008  loss: 1.7448  loss: 1.9763  loss: 2.0251  loss: 1.8187  loss: 2.2420  loss: 1.8710  loss: 1.9742  loss: 1.9714  loss: 2.0606  loss: 1.7388  loss: 1.7463  loss: 1.8116  loss: 1.8798  loss: 1.7868  loss: 1.9425 \n",
      "----- Accuracy: 0.284000 -----\n",
      "\n",
      "--kill worse 0\n",
      "DNA [ 11 ]销毁->fitness 0.344\n",
      "pop sum:  5 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 18 ) \n",
      "--reproduce better 4\n",
      "outputs_mutable 1 0\n",
      "pop sum:  6 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 18 ) ( 5 -> 19 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_1 \n",
      "vertex [ 3 ].0 , 2.c_1 \n",
      "vertex [ 4 ].0 , 0.c_3 , 3.i_1 , 1.i_3 \n",
      "[decode].[ 19 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=7, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1540  loss: 2.0435  loss: 2.1027  loss: 2.0096  loss: 2.1084  loss: 2.0885  loss: 2.0116  loss: 2.3506  loss: 2.0005  loss: 1.9398  loss: 2.0375  loss: 2.0522  loss: 2.3818  loss: 2.0680  loss: 2.0616  loss: 2.0681 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.0812  loss: 2.0822  loss: 2.3486  loss: 2.3745  loss: 2.0969  loss: 2.0136  loss: 1.9831  loss: 2.1799  loss: 2.0693  loss: 2.0889  loss: 2.1403  loss: 1.9729  loss: 1.8567  loss: 2.1780  loss: 1.9538  loss: 2.2542 \n",
      "----- Accuracy: 0.308000 -----\n",
      "\n",
      "--kill worse 5\n",
      "DNA [ 19 ]销毁->fitness 0.308\n",
      "pop sum:  5 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 18 ) \n",
      "--reproduce better 0\n",
      "[add_edge]->conv: 1 3\n",
      "pop sum:  6 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 18 ) ( 5 -> 20 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 0.i_3 , 1.c_4 \n",
      "vertex [ 3 ].0 , 0.c_5 , 2.i_7 , 1.c_2 \n",
      "[decode].[ 20 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=14, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1774  loss: 1.9195  loss: 1.7382  loss: 2.0101  loss: 1.9428  loss: 1.8092  loss: 2.0136  loss: 1.9652  loss: 1.9028  loss: 1.7867  loss: 1.7585  loss: 1.6043  loss: 2.1237  loss: 1.9939  loss: 2.0326  loss: 1.6904 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.7046  loss: 1.6972  loss: 1.8673  loss: 1.7265  loss: 1.7749  loss: 1.7962  loss: 1.8567  loss: 1.7617  loss: 1.7789  loss: 1.6904  loss: 1.8775  loss: 1.9688  loss: 1.7084  loss: 1.7379  loss: 1.8736  loss: 1.8987 \n",
      "----- Accuracy: 0.360000 -----\n",
      "\n",
      "--kill worse 4\n",
      "DNA [ 18 ]销毁->fitness 0.284\n",
      "pop sum:  5 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 20 ) \n",
      "--reproduce better 4\n",
      "pop sum:  6 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 20 ) ( 5 -> 21 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 0.i_3 , 1.c_4 \n",
      "vertex [ 3 ].0 , 2.i_7 , 0.c_5 , 1.c_2 \n",
      "[decode].[ 21 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=14, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): None\n",
      "    (5): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 2.1218  loss: 1.9739  loss: 2.0657  loss: 2.1858  loss: 2.3287  loss: 1.8956  loss: 1.7782  loss: 1.8097  loss: 1.8492  loss: 2.0777  loss: 1.7663  loss: 2.0073  loss: 1.7659  loss: 1.7668  loss: 2.0931  loss: 1.8404 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]ss: 1.6484  loss: 1.5863  loss: 1.7442  loss: 1.9138  loss: 1.8149  loss: 1.8393  loss: 1.7767  loss: 1.9386  loss: 1.8567  loss: 1.9011  loss: 1.8673  loss: 2.0195  loss: 2.0382  loss: 1.8221  loss: 1.7295  loss: 1.6563 \n",
      "----- Accuracy: 0.352000 -----\n",
      "\n",
      "--kill worse 5\n",
      "DNA [ 21 ]销毁->fitness 0.352\n",
      "pop sum:  5 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 20 ) \n",
      "--reproduce better 0\n",
      "outputs_mutable 1 0\n",
      "pop sum:  6 | ( 0 -> 12 ) ( 1 -> 13 ) ( 2 -> 15 ) ( 3 -> 17 ) ( 4 -> 20 ) ( 5 -> 22 ) \n",
      "vertex [ 1 ].0 , 0.i_3 \n",
      "vertex [ 2 ].0 , 1.c_0 \n",
      "vertex [ 3 ].0 , 0.i_3 , 2.c_0 \n",
      "vertex [ 4 ].0 , 3.i_3 , 0.c_5 \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf7c881b6224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# test = Evolution_pop(train_loader, test_x, test_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvolution_pop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_varition_dna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-f3aef908f5e7>\u001b[0m in \u001b[0;36mchoose_varition_dna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evolve_time\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evolve_time\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m             \u001b[1;31m# 每次挑两个个体并提取出训练成绩fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[0mindividual_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f3aef908f5e7>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;31m# TODO: 新训练的个体将fitness加入fitness_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mdna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[decode].[\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdna_cnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f3aef908f5e7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, DNA)\u001b[0m\n\u001b[0;32m    272\u001b[0m                                                  edge.filter_half_width * 2 + 1),\n\u001b[0;32m    273\u001b[0m                                     \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                                     padding=(edge.filter_half_height, edge.filter_half_width)))\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_edge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[0;32m    330\u001b[0m         super(Conv2d, self).__init__(\n\u001b[0;32m    331\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fan_in'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \"\"\"\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mfan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[0mgain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36m_calculate_correct_fan\u001b[1;34m(tensor, mode)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mode {} not supported, please use one of {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_modes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[0mfan_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfan_in\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fan_in'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\softwar\\academic\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36m_calculate_fan_in_and_fan_out\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mreceptive_field_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mreceptive_field_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[0mfan_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_input_fmaps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mreceptive_field_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mfan_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_output_fmaps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mreceptive_field_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = MadeDate()\n",
    "    # data.mnist()\n",
    "    # 数据集选择\n",
    "    # train_loader, test_x, test_y = data.getData()\n",
    "    # train_loader, test_x, test_y = data.mnist()\n",
    "    train_loader, testloader = data.CIFR10()\n",
    "\n",
    "    # test = Evolution_pop(train_loader, test_x, test_y)\n",
    "    test = Evolution_pop(data)\n",
    "    test.choose_varition_dna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
