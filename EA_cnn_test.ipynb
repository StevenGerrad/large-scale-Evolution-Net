{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set contains the following mutations:\n",
    "\n",
    "# • 学习率 ALTER-LEARNING-RATE (sampling details below).\n",
    "# • 线性 IDENTITY (effectively means “keep training”).\n",
    "# • 权重 RESET-WEIGHTS (sampled as in He et al. (2015), for\n",
    "#       example).\n",
    "# • 增 INSERT-CONVOLUTION (inserts a convolution at a random location in the “convolutional\n",
    "#       backbone”, as in Figure 1. The inserted convolution has 3 × 3 filters, strides\n",
    "#       of 1 or 2 at random, number of channels same as input.May apply batch-normalization\n",
    "#       and ReLU activation or none at random).\n",
    "# • 删 REMOVE-CONVOLUTION.\n",
    "# • 步长 ALTER-STRIDE (only powers of 2 are allowed).\n",
    "# • 通道数 ALTER-NUMBER-OF-CHANNELS (of random conv.).\n",
    "# • 滤波器大小 FILTER-SIZE (horizontal or vertical at random, on random convolution, odd values only).\n",
    "# • INSERT-ONE-TO-ONE (inserts a one-to-one/identity\n",
    "#       connection, analogous to insert-convolution mutation).\n",
    "# • 增跳层 ADD-SKIP (identity between random layers).\n",
    "# • 删跳层 REMOVE-SKIP (removes random skip).\n",
    "\n",
    "# 主要的组合实际为: conv+bn+relu\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# OUR--MLP\n",
    "\n",
    "# 学习率α\n",
    "# 增layer\n",
    "# 增skip\n",
    "# 设置'linear'/'relu'\n",
    "\n",
    "# 设置layer:\n",
    "#   out_channels\n",
    "#   kernel_size\n",
    "#   stride\n",
    "#   padding\n",
    "\n",
    "# 1.每次挑选两个个体, 确保个体已经被训练过了\n",
    "# 2.挑选个体的fitness，(population过大->kill不好的)，反之(population过小->reproduce好的)\n",
    "\n",
    "# Questiuon:\n",
    "# 1. depth_factor 来决定channel, channel要是变小那么depth_factor是小数？若乘积结果不是整数需要取整\n",
    "# 2. 仍要控制输出分类结果为one-hot\n",
    "# 3. 是否默认维持 padding : 是\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "DNA_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DNA(object):\n",
    "    '''\n",
    "    learning_rate, vertices[vertex_id]+type, edges[edge_id]\n",
    "    由vertex(linear / bn_relu), 和 edge(conv / identity)组成\n",
    "    '''\n",
    "    # __dna_cnt = 0\n",
    "    input_size_height = 32\n",
    "    input_size_width = 32\n",
    "    input_size_channel = 3\n",
    "\n",
    "    output_size_height = 1\n",
    "    output_size_width = 1\n",
    "    output_size_channel = 10\n",
    "\n",
    "    def __init__(self, learning_rate=0.05):\n",
    "        '''\n",
    "        注意，vertice 和 edges 中应该存引用\n",
    "        '''\n",
    "        global DNA_cnt\n",
    "        self.dna_cnt = DNA_cnt\n",
    "        DNA_cnt += 1\n",
    "        self.fitness = -1.0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # input layer\n",
    "        l0 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='identity',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        # Global Pooling layer\n",
    "        l1 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='identity',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        # output layer\n",
    "        l2 = Vertex(edges_in=set(),\n",
    "                    edges_out=set(),\n",
    "                    type='Global Pooling',\n",
    "                    inputs_mutable=0,\n",
    "                    outputs_mutable=0,\n",
    "                    properties_mutable=0)\n",
    "        self.vertices = []\n",
    "        self.vertices.append(l0)\n",
    "        self.vertices.append(l1)\n",
    "        self.vertices.append(l2)\n",
    "\n",
    "        # edge\n",
    "        edg1 = Edge(from_vertex=l0, to_vertex=l1, type='linear')\n",
    "        edg2 = Edge(from_vertex=l1, to_vertex=l2, type='linear')\n",
    "\n",
    "        edg1.input_channel = self.input_size_channel\n",
    "        edg1.output_channel = self.input_size_channel\n",
    "        self.edges = []\n",
    "        self.edges.append(edg1)\n",
    "        self.edges.append(edg2)\n",
    "\n",
    "        l0.edges_out.add(edg1)\n",
    "        l1.edges_in.add(edg1), l1.edges_out.add(edg2)\n",
    "        l2.edges_in.add(edg2)\n",
    "\n",
    "    def __del__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        print(class_name, \"[\", self.dna_cnt, \"]销毁->fitness\", self.fitness, end='\\n')\n",
    "\n",
    "    def add_edge(self,\n",
    "                 from_vertex_id,\n",
    "                 to_vertex_id,\n",
    "                 edge_type='identity',\n",
    "                 depth_factor=None,\n",
    "                 filter_half_width=None,\n",
    "                 filter_half_height=None,\n",
    "                 stride_scale=None):\n",
    "        \"\"\"\n",
    "        Adds an edge to the DNA graph, ensuring internal consistency.\n",
    "        \"\"\"\n",
    "        edge = Edge(from_vertex=self.vertices[from_vertex_id],\n",
    "                    to_vertex=self.vertices[to_vertex_id],\n",
    "                    type=edge_type,\n",
    "                    depth_factor=depth_factor,\n",
    "                    filter_half_width=filter_half_width,\n",
    "                    filter_half_height=filter_half_height,\n",
    "                    stride_scale=stride_scale)\n",
    "        self.edges.append(edge)\n",
    "        self.vertices[from_vertex_id].edges_out.add(edge)\n",
    "        self.vertices[to_vertex_id].edges_in.add(edge)\n",
    "        return edge\n",
    "\n",
    "    def calculate_flow(self):\n",
    "        '''\n",
    "        按顺序计算神经网络每层的输入输出参数\n",
    "        '''\n",
    "        self.vertices[0].input_channel = self.input_size_channel\n",
    "        # self.vertices[0].output_channel = self.input_size_channel\n",
    "        # self.vertices[-1].input_channel = self.output_size_channel\n",
    "        # self.vertices[-1].output_channel = self.output_size_channel\n",
    "\n",
    "        for vertex in self.vertices[1:]:\n",
    "            for edge in vertex.edges_in:\n",
    "                edge.input_channel = edge.from_vertex.input_channel\n",
    "                edge.output_channel = int(edge.input_channel * edge.depth_factor)\n",
    "                vertex.input_channel += edge.output_channel\n",
    "\n",
    "    def mutate_layer_size(self, v_list=[], s_list=[]):\n",
    "        for i in range(len(v_list)):\n",
    "            self.vertices[v_list[i]].outputs_mutable = s_list[i]\n",
    "\n",
    "    def add_vertex(self, after_vertex_id, vertex_type='linear', edge_type='identity'):\n",
    "        '''\n",
    "        3.0: 所有 vertex 和 edg 中记录的都是引用\n",
    "        '''\n",
    "        changed_edge = None\n",
    "        # 先寻找那条应该被移除的边, 将其删除\n",
    "        for i in self.vertices[after_vertex_id - 1].edges_out:\n",
    "            if i.to_vertex == self.vertices[after_vertex_id]:\n",
    "                self.vertices[after_vertex_id - 1].edges_out.remove(i)\n",
    "                break\n",
    "        for i in self.vertices[after_vertex_id].edges_in:\n",
    "            if i.from_vertex == self.vertices[after_vertex_id - 1]:\n",
    "                self.vertices[after_vertex_id].edges_in.remove(i)\n",
    "                break\n",
    "        for i, edge in enumerate(self.edges):\n",
    "            if edge.from_vertex == self.vertices[\n",
    "                    after_vertex_id - 1] and edge.to_vertex == self.vertices[after_vertex_id]:\n",
    "                changed_edge = self.edges[i]\n",
    "\n",
    "        # 创建新的 vertex, 并加入队列\n",
    "        vertex_add = Vertex(edges_in=set(), edges_out=set(), type=vertex_type)\n",
    "        self.vertices.insert(after_vertex_id, vertex_add)\n",
    "\n",
    "        # 创建新的 edge, 并加入队列\n",
    "        if edge_type == 'conv':\n",
    "            depth_f = random.random() * 2\n",
    "            filter_h = 1\n",
    "            filter_w = 1\n",
    "            edge_add1 = Edge(from_vertex=self.vertices[after_vertex_id - 1],\n",
    "                             to_vertex=self.vertices[after_vertex_id],\n",
    "                             type='conv',\n",
    "                             depth_factor=depth_f,\n",
    "                             filter_half_height=filter_h,\n",
    "                             filter_half_width=filter_w,\n",
    "                             stride_scale=1)\n",
    "        else:\n",
    "            edge_add1 = Edge(from_vertex=self.vertices[after_vertex_id - 1],\n",
    "                             to_vertex=self.vertices[after_vertex_id],\n",
    "                             type='linear')\n",
    "        # 取代的那条边后移\n",
    "        changed_edge.from_vertex = self.vertices[after_vertex_id]\n",
    "        # edge_add2 = Edge(from_vertex=self.vertices[after_vertex_id],to_vertex=self.vertices[after_vertex_id + 1])\n",
    "        self.edges.append(edge_add1)\n",
    "        # self.edges.append(edge_add2)\n",
    "\n",
    "        self.vertices[after_vertex_id - 1].edges_out.add(edge_add1)\n",
    "        vertex_add.edges_in.add(edge_add1), vertex_add.edges_out.add(changed_edge)\n",
    "        self.vertices[after_vertex_id + 1].edges_in.add(changed_edge)\n",
    "\n",
    "    def has_edge(self, from_vertex_id, to_vertex_id):\n",
    "        vertex_before = self.vertices[from_vertex_id]\n",
    "        vertex_after = self.vertices[to_vertex_id]\n",
    "        for edg in self.edges:\n",
    "            if edg.from_vertex == vertex_before and edg.to_vertex == vertex_after:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Vertex(object):\n",
    "    '''\n",
    "    edges_in, edges_out, HasField(bn_relu/linear), \n",
    "    inputs_mutable, outputs_mutable, properties_mutable\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 edges_in,\n",
    "                 edges_out,\n",
    "                 type='linear',\n",
    "                 inputs_mutable=1,\n",
    "                 outputs_mutable=1,\n",
    "                 properties_mutable=1):\n",
    "        '''\n",
    "        edges_in / edges_out : 使用set \n",
    "        each vertex can be inlear / 1*relu + 1*bn\n",
    "        '''\n",
    "        self.edges_in = edges_in\n",
    "        self.edges_out = edges_out\n",
    "        self.type = type  # ['linear' / 'bn_relu']\n",
    "\n",
    "        self.inputs_mutable = inputs_mutable\n",
    "        self.outputs_mutable = outputs_mutable\n",
    "        self.properties_mutable = properties_mutable\n",
    "\n",
    "        self.input_channel = 0\n",
    "        # Each vertex represents a 2ˆs x 2ˆs x d block of nodes. s and d are positive\n",
    "        # integers computed dynamically from the in-edges. s stands for \"scale\" so\n",
    "        # that 2ˆx x 2ˆs is the spatial size of the activations. d stands for \"depth\",\n",
    "        # the number of channels.\n",
    "\n",
    "\n",
    "class Edge(object):\n",
    "    '''\n",
    "    No Need:type, depth_factor, filter_half_width, filter_half_height, \n",
    "            stride_scale, depth_precedence, scale_precedence\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 from_vertex,\n",
    "                 to_vertex,\n",
    "                 type='identity',\n",
    "                 depth_factor=1,\n",
    "                 filter_half_width=None,\n",
    "                 filter_half_height=None,\n",
    "                 stride_scale=None):\n",
    "        self.from_vertex = from_vertex  # Source vertex ID.\n",
    "        self.to_vertex = to_vertex  # Destination vertex ID.\n",
    "        self.type = type\n",
    "\n",
    "        # In this case, the edge represents a convolution.\n",
    "        # 控制 channel 大小, this.channel = last channel * depth_factor\n",
    "        self.depth_factor = depth_factor\n",
    "        if type == 'conv':\n",
    "            # 卷积核 size\n",
    "            # filter_width = 2 * filter_half_width + 1.\n",
    "            self.filter_half_width = filter_half_width\n",
    "            self.filter_half_height = filter_half_height\n",
    "            # 定义卷积步长, 卷积步长必须是 2 的幂次方？\n",
    "            # Controls the strides(步幅) of the convolution. It will be 2ˆstride_scale. WHY ?????\n",
    "            self.stride_scale = stride_scale\n",
    "\n",
    "        # determine the inputs takes precedence in deciding the resolved depth or scale.\n",
    "        # self.depth_precedence = edge_proto.depth_precedence\n",
    "        # self.scale_precedence = edge_proto.scale_precedence\n",
    "\n",
    "        self.input_channel = 0\n",
    "        self.output_channel = 0\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, DNA):\n",
    "        super(Model, self).__init__()\n",
    "        self.dna = DNA\n",
    "        self.layer_vertex = torch.nn.ModuleList()\n",
    "        for vertex in DNA.vertices:\n",
    "            # 默认第一层和最后一层 vertex 非 hidden 层\n",
    "            if vertex.type == 'bn_relu':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(torch.nn.BatchNorm2d(vertex.input_channel),\n",
    "                                        torch.nn.ReLU(inplace=True)))\n",
    "            elif vertex.type == 'Global Pooling':\n",
    "                self.layer_vertex.append(\n",
    "                    torch.nn.Sequential(\n",
    "                        # torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                        torch.nn.Linear(vertex.input_channel, DNA.output_size_channel)))\n",
    "            else:\n",
    "                self.layer_vertex.append(None)\n",
    "\n",
    "        self.layer_edge = torch.nn.ModuleList()\n",
    "        for edge in DNA.edges:\n",
    "            # TODO: 默认padding补全\n",
    "            if edge.type == 'conv':\n",
    "                self.layer_edge.append(\n",
    "                    torch.nn.Conv2d(edge.input_channel,\n",
    "                                    edge.output_channel,\n",
    "                                    kernel_size=(edge.filter_half_height * 2 + 1,\n",
    "                                                 edge.filter_half_width * 2 + 1),\n",
    "                                    stride=pow(2, edge.stride_scale),\n",
    "                                    padding=(edge.filter_half_height, edge.filter_half_width)))\n",
    "            else:\n",
    "                self.layer_edge.append(None)\n",
    "        self.batch_size = Evolution_pop.BATCH_SIZE\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        配置每层的 输入、输出、激活函数\n",
    "        '''\n",
    "        block_h = input.shape[0]\n",
    "        x = {\n",
    "            0: input,\n",
    "        }\n",
    "        for index, layer_vert in enumerate(self.layer_vertex[1:], start=1):\n",
    "            length = len(x)\n",
    "\n",
    "            a = torch.empty(block_h, 0, 0, 0)\n",
    "            for j, edg in enumerate(self.dna.vertices[index].edges_in):\n",
    "                ind_edg = self.dna.edges.index(edg)\n",
    "                ind_x = self.dna.vertices.index(edg.from_vertex)\n",
    "                t = x[ind_x]\n",
    "                if edg.type == 'conv':\n",
    "                    t = self.layer_edge[ind_edg](x[ind_x])\n",
    "                if j == 0:\n",
    "                    a = torch.empty(block_h, 0, t.shape[2], t.shape[3])\n",
    "                a = torch.cat((a, t), dim=1)\n",
    "\n",
    "            if self.dna.vertices[index].type == 'identity':\n",
    "                x[index] = a\n",
    "            elif self.dna.vertices[index].type == 'bn_relu':\n",
    "                x[index] = layer_vert(a)\n",
    "            elif self.dna.vertices[index].type == 'Global Pooling':\n",
    "                temp = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "                a = temp(a)\n",
    "                a = torch.squeeze(a, 3)\n",
    "                a = torch.squeeze(a, 2)\n",
    "                x[index] = layer_vert(a)\n",
    "\n",
    "        return x[len(x) - 1]\n",
    "\n",
    "\n",
    "class StructMutation():\n",
    "    '''\n",
    "    can mutate: hidden size, add edge, learning rate, add vertex, \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self._edge_types = []\n",
    "\n",
    "    def mutate(self, dna):\n",
    "        '''\n",
    "        TODO: 可能出现由于概率'没有任何变异'的情况，不能让其发生\n",
    "        1. 添加边时：添加identity, 则矩阵拼接时需要维度匹配 / 添加conv则需要是设置好参数\n",
    "        '''\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        # 1. Try the candidates in random order until one has the right connectivity.(Add)\n",
    "        for from_vertex_id, to_vertex_id in self._vertex_pair_candidates(dna):\n",
    "            if random.random() > 0.5:\n",
    "                self._mutate_structure(mutated_dna, from_vertex_id, to_vertex_id)\n",
    "\n",
    "        # 2. Try to mutate learning Rate\n",
    "        self.mutate_learningRate(mutated_dna)\n",
    "\n",
    "        # 3. mutate the hidden layer's size\n",
    "        # self.mutate_hidden_size(dna)\n",
    "\n",
    "        # 4. Mutate the vertex (Add)\n",
    "        # self.mutate_vertex(mutated_dna)\n",
    "        if random.random() > 0.4:\n",
    "            self.mutate_vertex(mutated_dna)\n",
    "        return mutated_dna\n",
    "\n",
    "    def _vertex_pair_candidates(self, dna):\n",
    "        \"\"\"Yields connectable vertex pairs.\"\"\"\n",
    "        from_vertex_ids = self._find_allowed_vertices(dna)\n",
    "        # if not from_vertex_ids: raise exceptions.MutationException(), 打乱次序\n",
    "        random.shuffle(from_vertex_ids)\n",
    "\n",
    "        to_vertex_ids = self._find_allowed_vertices(dna)\n",
    "        # if not to_vertex_ids: raise exceptions.MutationException()\n",
    "        random.shuffle(to_vertex_ids)\n",
    "\n",
    "        for to_vertex_id in to_vertex_ids:\n",
    "            # Avoid back-connections. TODO: 此处可能会涉及到 拓扑图的顺序判断\n",
    "            # disallowed_from_vertex_ids, _ = topology.propagated_set(to_vertex_id)\n",
    "            disallowed_from_vertex_ids = self._find_disallowed_from_vertices(dna, to_vertex_id)\n",
    "            for from_vertex_id in from_vertex_ids:\n",
    "                if from_vertex_id in disallowed_from_vertex_ids:\n",
    "                    continue\n",
    "                # This pair does not generate a cycle, so we yield it.\n",
    "                yield from_vertex_id, to_vertex_id\n",
    "\n",
    "    def _find_allowed_vertices(self, dna):\n",
    "        ''' TODO: 除第一层(假节点)外的所有vertex_id '''\n",
    "        return list(range(0, len(dna.vertices)))\n",
    "\n",
    "    def _find_disallowed_from_vertices(self, dna, to_vertex_id):\n",
    "        ''' 寻找不可作为起始层索引的：反向链接的，重复连接的Edge '''\n",
    "        res = list(range(to_vertex_id, len(dna.vertices)))\n",
    "        # 排查每个 vertex 是否不符合, 即索引在前面的 vertex 的所有 edges_out\n",
    "        for i, vertex in enumerate(dna.vertices[:to_vertex_id]):\n",
    "            for edge in vertex.edges_out:\n",
    "                if dna.vertices.index(edge.to_vertex) == to_vertex_id:\n",
    "                    if i not in res:\n",
    "                        res.append(i)\n",
    "                        continue\n",
    "        return res\n",
    "\n",
    "    def _mutate_structure(self, dna, from_vertex_id, to_vertex_id):\n",
    "        \"\"\"Adds the edge to the DNA instance.\"\"\"\n",
    "        if dna.has_edge(from_vertex_id, to_vertex_id):\n",
    "            return False\n",
    "        else:\n",
    "            print(\"[_mutate_structure]->prepare to :\", from_vertex_id, to_vertex_id)\n",
    "            # TODO: edge 有两个类型，identity 和 conv (主要调节 stride, 在默认padding补全的情况下)\n",
    "            # 1. 若数据维度不变，可以用identity， 则需要检查 stride 是否不变\n",
    "            res = True\n",
    "            bin_stride = 1\n",
    "            for vertex_id, vert in enumerate(dna.vertices[from_vertex_id + 1:to_vertex_id]):\n",
    "                edg_direct = vert.edges_in[0]\n",
    "                for edg in vert.edges_in[1:]:\n",
    "                    if edg.from_vertex == dna.vertices[\n",
    "                            vertex_id - 1] and edg.to_vertex == dna.vertices[vertex_id]:\n",
    "                        edg_direct = edg\n",
    "                        break\n",
    "                if edg_direct.stride != 1:\n",
    "                    res = False\n",
    "                    bin_stride *= edg_direct.stride\n",
    "            if res:\n",
    "                new_edge = dna.add_edge(from_vertex_id, to_vertex_id)\n",
    "                return res\n",
    "            # 2. 若数据维度改变(变小)，要用conv\n",
    "            depth_f = random.random() * 2\n",
    "            filter_h = 1\n",
    "            filter_w = 1\n",
    "            new_edge = dna.add_edge(from_vertex_id,\n",
    "                                    to_vertex_id,\n",
    "                                    edge_type='identity',\n",
    "                                    depth_factor=depth_f,\n",
    "                                    filter_half_height=filter_h,\n",
    "                                    filter_half_width=filter_w,\n",
    "                                    stride_scale=bin_stride)\n",
    "            return True\n",
    "\n",
    "    def mutate_hidden_size(self, dna):\n",
    "        '''\n",
    "        TODO: mutate the hidden layer's size \n",
    "        高斯分布随机生成, 对所有 hidden layer 变动...不可取\n",
    "        '''\n",
    "        # for i in list(range(1, len(dna.vertices) - 1)):\n",
    "        #     if random.random() > 0.6:\n",
    "        #         last = dna.vertices[i].outputs_mutable\n",
    "        #         before = dna.vertices[i - 1].outputs_mutable\n",
    "        #         after = dna.vertices[i + 1].outputs_mutable\n",
    "\n",
    "        #         alpha = min(before - last, last - after) / 3\n",
    "        #         next = last + alpha * np.random.randn(1)\n",
    "        #         next = int(next[0])\n",
    "        #         if next > before:\n",
    "        #             next = before\n",
    "        #         elif next < after:\n",
    "        #             next = after\n",
    "        #         dna.vertices[i].outputs_mutable = next\n",
    "\n",
    "    def mutate_learningRate(self, dna):\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        # Mutate the learning rate by a random factor between 0.5 and 2.0,\n",
    "        # uniformly distributed in log scale.\n",
    "        factor = 2**random.uniform(-1.0, 1.0)\n",
    "        mutated_dna.learning_rate = dna.learning_rate * factor\n",
    "        return mutated_dna\n",
    "\n",
    "    def mutate_vertex(self, dna):\n",
    "        # mutated_dna = copy.deepcopy(dna)\n",
    "        mutated_dna = dna\n",
    "        # 随机选择一个 vertex_id 插入 vertex\n",
    "        after_vertex_id = random.choice(self._find_allowed_vertices(dna))\n",
    "        if after_vertex_id == 0:\n",
    "            return mutated_dna\n",
    "\n",
    "        print('outputs_mutable', dna.vertices[after_vertex_id].outputs_mutable,\n",
    "              dna.vertices[after_vertex_id - 1].outputs_mutable)\n",
    "        # TODO: how it supposed to mutate\n",
    "        vertex_type = 'linear'\n",
    "        if random.random() > 0.2:\n",
    "            vertex_type = 'bn_relu'\n",
    "\n",
    "        edge_type = 'identity'\n",
    "        if random.random() > 0.2:\n",
    "            edge_type = 'conv'\n",
    "\n",
    "        mutated_dna.add_vertex(after_vertex_id, after_vertex_id, vertex_type, edge_type)\n",
    "        return mutated_dna\n",
    "\n",
    "\n",
    "class Evolution_pop:\n",
    "    _population_size_setpoint = 5\n",
    "    _max_layer_size = 4\n",
    "    _evolve_time = 100\n",
    "    fitness_pool = []\n",
    "\n",
    "    EPOCH = 2  # 训练整批数据多少次\n",
    "    BATCH_SIZE = 50\n",
    "    N_CLASSES = 10\n",
    "\n",
    "    # LR = 0.001          # 学习率\n",
    "\n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        初始化DNA: 一层hidden(节点数不同); 都为linear\n",
    "        接收传入的训练数据 data\n",
    "        初始化 Mutation 类\n",
    "        '''\n",
    "        self.population = []\n",
    "        for i in range(self._population_size_setpoint):\n",
    "            dna_iter = DNA()\n",
    "            self.population.append(dna_iter)\n",
    "        self.data = data\n",
    "        self.struct_mutation = StructMutation()\n",
    "\n",
    "    def decode(self):\n",
    "        '''\n",
    "         对当前population队列中的每个未训练过的个体进行训练 \n",
    "         https://www.cnblogs.com/denny402/p/7520063.html\n",
    "        '''\n",
    "        for dna in self.population:\n",
    "            if dna.fitness != -1.0:\n",
    "                continue\n",
    "            # TODO: 新训练的个体将fitness加入fitness_pool\n",
    "            dna.calculate_flow()\n",
    "            net = Model(dna)\n",
    "            print(\"[decode].[\", dna.dna_cnt, \"]\", net)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=dna.learning_rate)\n",
    "            # the target label is not one-hotted\n",
    "            loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_loader, testloader = self.data.getData()\n",
    "\n",
    "            # print(\"[Evolution_pop].[decode]->test_x: \", test_x.shape)\n",
    "            accuracy = 0\n",
    "            # training and testing\n",
    "            for epoch in range(self.EPOCH):\n",
    "                step = 0\n",
    "                # TODO: 用movan的enumerate会报错，why?\n",
    "                max_tep = int(60000 / train_loader.batch_size)\n",
    "\n",
    "                train_acc = .0\n",
    "                len_y = 0\n",
    "                for step, (b_x, b_y) in enumerate(train_loader):\n",
    "                    # print(\"[b_x, b_y].shape: \", b_x.shape, b_y.shape)\n",
    "                    # 分配 batch data, normalize x when iterate train_loader\n",
    "                    output = net(b_x)  # cnn output\n",
    "                    idy = b_y.view(-1, 1)\n",
    "                    # b_y = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, idy, 1).long()\n",
    "\n",
    "                    loss = loss_func(output, b_y)  # cross entropy loss\n",
    "                    # clear gradients for this training step\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()  # backpropagation, compute gradients\n",
    "                    optimizer.step()  # apply gradients\n",
    "\n",
    "                    # target = torch.zeros(self.BATCH_SIZE, 10).scatter_(1, idy, 1).long()\n",
    "                    # train_correct = (output == target).sum()\n",
    "                    # train_acc += train_correct.data[0]\n",
    "                    # len_y += len(target)\n",
    "\n",
    "                    if step % 50 == 0:\n",
    "                        pred = net(b_x)\n",
    "\n",
    "                        # pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "                        # accuracy = float(\n",
    "                        #     (pred_y == test_y.data.numpy()).astype(int).sum()) / float(\n",
    "                        #         test_y.size(0))\n",
    "\n",
    "                        accuracy = self.Accuracy(net, testloader)\n",
    "                        # print('Epoch: ', epoch, 'step: ', step,'| train loss: %.4f' % loss.data.numpy(),'| test accuracy: %.2f' % accuracy)\n",
    "                        print(\"\\r\" + 'Epoch: ' + str(epoch) + ' step: ' + str(step) + '[' +\n",
    "                              \">>\" * int(step / 50) + ']',\n",
    "                              end=' ')\n",
    "                        # print('loss: %.4f' % loss.data.numpy(),'| accuracy: %.4f' % train_acc / len_y,end=' ')\n",
    "                        print('loss: %.4f' % loss.data.numpy(),\n",
    "                              '| accuracy: %.4f' % accuracy,\n",
    "                              end=' ')\n",
    "\n",
    "                print('')\n",
    "            accuracy = self.Accuracy(net, testloader)\n",
    "\n",
    "            # dna.fitness = eval_acc / len_y\n",
    "            dna.fitness = accuracy\n",
    "            print('')\n",
    "\n",
    "    def Accuracy(self, net, testloader):\n",
    "        ''' https://blog.csdn.net/Arctic_Beacon/article/details/85068188 '''\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "        class_correct = list(0. for i in range(self.N_CLASSES))\n",
    "        class_total = list(0. for i in range(self.N_CLASSES))\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == labels).squeeze()\n",
    "                for i in range(self.BATCH_SIZE):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        # for i in range(self.N_CLASSES):\n",
    "        #     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        return sum(class_correct) / sum(class_total)\n",
    "\n",
    "    def choose_varition_dna(self):\n",
    "        '''\n",
    "        每次挑选两个体,取fitness,判断要kill还是reproduce\n",
    "        '''\n",
    "        while self._evolve_time > 0:\n",
    "            self._evolve_time -= 1\n",
    "            self.decode()\n",
    "            # 每次挑两个个体并提取出训练成绩fitness\n",
    "            individual_pair = random.sample(list(enumerate(self.population)), 2)\n",
    "            # TODO: 话说他这样取出来如果删掉的话真的能保证吗\n",
    "            individual_pair.sort(key=lambda i: i[1].fitness, reverse=True)\n",
    "            # better_individual = individual_pair[0]\n",
    "            # worse_individual = individual_pair[1]\n",
    "            # print(\"Choice: \",self._evolve_time,end=' ')\n",
    "            # print(\"better: \",better_individual[0],'->',better_individual[1].fitness, end=' ')\n",
    "            # print(\"worse: \", worse_individual[0],'->', worse_individual[1].fitness, end=' ')\n",
    "            better_individual = individual_pair[0][0]\n",
    "            worse_individual = individual_pair[1][0]\n",
    "            individual_pair = []\n",
    "            # (population过大->kill不好的)，反之(population过小->reproduce好的)\n",
    "            if len(self.population) >= self._population_size_setpoint:\n",
    "                print(\"--kill worse\", worse_individual)\n",
    "                self._kill_individual(worse_individual)\n",
    "            elif len(self.population) < self._population_size_setpoint:\n",
    "                print(\"--reproduce better\", better_individual)\n",
    "                self._reproduce_and_train_individual(better_individual)\n",
    "\n",
    "    def _kill_individual(self, index):\n",
    "        ''' kill by the index of population '''\n",
    "        # self._print_population()\n",
    "\n",
    "        del self.population[index]\n",
    "        # debug\n",
    "        self._print_population()\n",
    "\n",
    "    def _reproduce_and_train_individual(self, index):\n",
    "        ''' \n",
    "        inherit the parent, mutate, join the population \n",
    "        为了节省时间实际上有 Weight Inheritance\n",
    "        '''\n",
    "        # self._print_population()\n",
    "\n",
    "        # inherit the parent (attention the dna_cnt)\n",
    "        son = self.inherit_DNA(self.population[index])\n",
    "\n",
    "        self.struct_mutation.mutate(son)\n",
    "        self.population.append(son)\n",
    "        # debug\n",
    "        self._print_population()\n",
    "\n",
    "    def inherit_DNA(self, dna):\n",
    "        ''' inderit from parent: reset dna_cnt, fitness '''\n",
    "        son = copy.deepcopy(dna)\n",
    "        global DNA_cnt\n",
    "        son.dna_cnt = DNA_cnt\n",
    "        DNA_cnt += 1\n",
    "        son.fitness = -1\n",
    "        return son\n",
    "\n",
    "    def _print_population(self):\n",
    "        print(\"pop sum: \", len(self.population), '|', end=' ')\n",
    "        index = 0\n",
    "        for i in self.population:\n",
    "            print('(', index, '->', i.dna_cnt, ')', end=' ')\n",
    "            index += 1\n",
    "        print('')\n",
    "\n",
    "\n",
    "class MadeDate:\n",
    "    DOWNLOAD_MNIST = False  # 如果你已经下载好了mnist数据就写上 False\n",
    "    DOWNLOAD_FSAHION_MNIST = False\n",
    "    BATCH_SIZE = 50\n",
    "\n",
    "    def __init__(self):\n",
    "        # Mnist digits dataset\n",
    "        '''\n",
    "        if not (os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "            # not mnist dir or mnist is empyt dir\n",
    "            self.DOWNLOAD_MNIST = True\n",
    "        if not (os.path.exists('./FashionMNIST/')) or not os.listdir('./FashionMNIST/'):\n",
    "            # not mnist dir or mnist is empyt dir\n",
    "            self.DOWNLOAD_FSAHION_MNIST = True\n",
    "        '''\n",
    "\n",
    "    def CIFR10(self):\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        # 定义了我们的训练集，名字就叫trainset，至于后面这一堆，其实就是一个类：\n",
    "        # torchvision.datasets.CIFAR10( )也是封装好了的，就在我前面提到的torchvision.datasets\n",
    "        # 模块中,不必深究，如果想深究就看我这段代码后面贴的图1，其实就是在下载数据\n",
    "        #（不翻墙可能会慢一点吧）然后进行变换，可以看到transform就是我们上面定义的transform\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./dataset',\n",
    "                                                train=True,\n",
    "                                                download=False,\n",
    "                                                transform=transform)\n",
    "        # trainloader其实是一个比较重要的东西，我们后面就是通过trainloader把数据传入网\n",
    "        # 络，当然这里的trainloader其实是个变量名，可以随便取，重点是他是由后面的\n",
    "        # torch.utils.data.DataLoader()定义的，这个东西来源于torch.utils.data模块，\n",
    "        #  网页链接http://pytorch.org/docs/0.3.0/data.html，这个类可见我后面图2\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                       batch_size=self.BATCH_SIZE,\n",
    "                                                       shuffle=True,\n",
    "                                                       num_workers=2)\n",
    "        # 对于测试集的操作和训练集一样，我就不赘述了\n",
    "        testset = torchvision.datasets.CIFAR10(root='./dataset',\n",
    "                                               train=False,\n",
    "                                               download=False,\n",
    "                                               transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                      batch_size=2000,\n",
    "                                                      shuffle=False,\n",
    "                                                      num_workers=2)\n",
    "\n",
    "        # 设置DNA的size\n",
    "        DNA.input_size_height = 32\n",
    "        DNA.input_size_width = 32\n",
    "        DNA.input_size_channel = 3\n",
    "        DNA.output_size_height = 1\n",
    "        DNA.output_size_width = 1\n",
    "        DNA.output_size_channel = 10\n",
    "        return self.trainloader, self.testloader\n",
    "\n",
    "    def getData(self):\n",
    "        return self.trainloader, self.testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[decode].[ 0 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.0893 | accuracy: 0.2200  loss: 2.2035 | accuracy: 0.2560  loss: 2.1908 | accuracy: 0.2280  loss: 2.2292 | accuracy: 0.2320  loss: 2.0710 | accuracy: 0.2440  loss: 2.2889 | accuracy: 0.2440  loss: 2.1730 | accuracy: 0.2600  loss: 2.0726 | accuracy: 0.2560  loss: 2.1536 | accuracy: 0.2640  loss: 2.0710 | accuracy: 0.2320  loss: 2.0711 | accuracy: 0.2480  loss: 2.0890 | accuracy: 0.2480  loss: 2.2610 | accuracy: 0.2440  loss: 1.9171 | accuracy: 0.2800  loss: 1.9813 | accuracy: 0.2400  loss: 2.1032 | accuracy: 0.2640  loss: 1.9852 | accuracy: 0.2280  loss: 2.1050 | accuracy: 0.2600  loss: 2.0981 | accuracy: 0.2440 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.1448 | accuracy: 0.2320  loss: 2.0166 | accuracy: 0.2720  loss: 2.0254 | accuracy: 0.2720  loss: 2.1626 | accuracy: 0.2800  loss: 2.1514 | accuracy: 0.2600  loss: 1.9590 | accuracy: 0.2320  loss: 2.0442 | accuracy: 0.2600  loss: 1.8724 | accuracy: 0.2640  loss: 2.0754 | accuracy: 0.2360  loss: 2.0423 | accuracy: 0.2560  loss: 2.1572 | accuracy: 0.2400  loss: 2.1452 | accuracy: 0.2560  loss: 1.9898 | accuracy: 0.2800  loss: 1.9299 | accuracy: 0.2840  loss: 2.1089 | accuracy: 0.2680  loss: 2.1340 | accuracy: 0.2520  loss: 2.2644 | accuracy: 0.2480  loss: 2.4140 | accuracy: 0.2760  loss: 2.0450 | accuracy: 0.2640 \n",
      "\n",
      "[decode].[ 1 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.1959 | accuracy: 0.2160  loss: 2.1710 | accuracy: 0.2120  loss: 2.0997 | accuracy: 0.2480  loss: 2.1827 | accuracy: 0.2600  loss: 2.1282 | accuracy: 0.2800  loss: 2.0014 | accuracy: 0.2200  loss: 1.9632 | accuracy: 0.2280  loss: 2.0389 | accuracy: 0.2480  loss: 2.1203 | accuracy: 0.2560  loss: 2.0124 | accuracy: 0.2560  loss: 2.0533 | accuracy: 0.2640  loss: 2.1198 | accuracy: 0.2800  loss: 2.0785 | accuracy: 0.2680  loss: 2.1989 | accuracy: 0.2600  loss: 2.2137 | accuracy: 0.2480  loss: 1.9040 | accuracy: 0.2840  loss: 2.1843 | accuracy: 0.2480  loss: 2.0698 | accuracy: 0.2680  loss: 2.3038 | accuracy: 0.2560 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.1654 | accuracy: 0.2920  loss: 2.1897 | accuracy: 0.2640  loss: 2.1730 | accuracy: 0.2440  loss: 1.9709 | accuracy: 0.2520  loss: 2.2731 | accuracy: 0.2560  loss: 2.0993 | accuracy: 0.2640  loss: 1.9712 | accuracy: 0.2640  loss: 2.1582 | accuracy: 0.2560  loss: 1.9766 | accuracy: 0.2600  loss: 1.9936 | accuracy: 0.2560  loss: 2.0374 | accuracy: 0.2600  loss: 1.9314 | accuracy: 0.2600  loss: 2.0664 | accuracy: 0.2440  loss: 1.9434 | accuracy: 0.2720  loss: 2.0770 | accuracy: 0.2520  loss: 2.1080 | accuracy: 0.2640  loss: 1.9121 | accuracy: 0.2560  loss: 2.1521 | accuracy: 0.2480  loss: 1.9914 | accuracy: 0.2760 \n",
      "\n",
      "[decode].[ 2 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.3027 | accuracy: 0.2360  loss: 2.0899 | accuracy: 0.2320  loss: 2.0081 | accuracy: 0.2840  loss: 2.1179 | accuracy: 0.2720  loss: 2.0997 | accuracy: 0.2680  loss: 2.0382 | accuracy: 0.3000  loss: 2.1236 | accuracy: 0.2320  loss: 2.1771 | accuracy: 0.2360  loss: 2.0863 | accuracy: 0.2520  loss: 2.0779 | accuracy: 0.2760  loss: 2.2034 | accuracy: 0.2920  loss: 2.0632 | accuracy: 0.2520  loss: 2.1865 | accuracy: 0.2760  loss: 2.0364 | accuracy: 0.2360  loss: 2.1330 | accuracy: 0.2760  loss: 2.0484 | accuracy: 0.2320  loss: 2.1225 | accuracy: 0.2640  loss: 2.0087 | accuracy: 0.2520  loss: 2.1006 | accuracy: 0.2840 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]1.8844 | accuracy: 0.2520  loss: 2.1215 | accuracy: 0.2760  loss: 2.0456 | accuracy: 0.2680  loss: 2.0740 | accuracy: 0.2720  loss: 2.0657 | accuracy: 0.2520  loss: 2.0068 | accuracy: 0.2480  loss: 2.0023 | accuracy: 0.2520  loss: 2.0646 | accuracy: 0.2640  loss: 2.0842 | accuracy: 0.2600  loss: 2.1662 | accuracy: 0.2520  loss: 1.9852 | accuracy: 0.2440  loss: 2.0059 | accuracy: 0.2560  loss: 2.0572 | accuracy: 0.2440  loss: 1.9348 | accuracy: 0.2600  loss: 2.2991 | accuracy: 0.2280  loss: 2.0061 | accuracy: 0.2560  loss: 1.9133 | accuracy: 0.2160  loss: 2.1063 | accuracy: 0.2400  loss: 2.1381 | accuracy: 0.2600 \n",
      "\n",
      "[decode].[ 3 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.2731 | accuracy: 0.2160  loss: 2.2291 | accuracy: 0.2560  loss: 2.1306 | accuracy: 0.2520  loss: 2.0094 | accuracy: 0.2520  loss: 1.9978 | accuracy: 0.2240  loss: 2.1073 | accuracy: 0.2640  loss: 2.1888 | accuracy: 0.2600  loss: 2.0996 | accuracy: 0.2200  loss: 2.0086 | accuracy: 0.2840  loss: 2.2140 | accuracy: 0.2280  loss: 2.0831 | accuracy: 0.2360  loss: 2.0804 | accuracy: 0.2800  loss: 2.0728 | accuracy: 0.2360  loss: 2.0531 | accuracy: 0.2680  loss: 2.2435 | accuracy: 0.2840  loss: 2.0770 | accuracy: 0.2520  loss: 2.2218 | accuracy: 0.2560  loss: 2.0696 | accuracy: 0.2480  loss: 2.0401 | accuracy: 0.2720 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.0883 | accuracy: 0.2560  loss: 2.1368 | accuracy: 0.2680  loss: 2.0532 | accuracy: 0.2560  loss: 2.0826 | accuracy: 0.2720  loss: 2.0417 | accuracy: 0.2440  loss: 2.0402 | accuracy: 0.2400  loss: 2.0012 | accuracy: 0.2640  loss: 2.0182 | accuracy: 0.2600  loss: 2.0835 | accuracy: 0.2520  loss: 2.3274 | accuracy: 0.2760  loss: 2.1569 | accuracy: 0.2680  loss: 2.1939 | accuracy: 0.2320  loss: 2.1831 | accuracy: 0.2800  loss: 2.2216 | accuracy: 0.2840  loss: 2.1441 | accuracy: 0.2600  loss: 1.9703 | accuracy: 0.2520  loss: 2.0279 | accuracy: 0.2600  loss: 1.9440 | accuracy: 0.2760  loss: 2.4704 | accuracy: 0.2440 \n",
      "\n",
      "[decode].[ 4 ] Model(\n",
      "  (layer_vertex): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_edge): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "  )\n",
      ")\n",
      "Epoch: 0 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.1723 | accuracy: 0.1800  loss: 2.1824 | accuracy: 0.1960  loss: 2.0777 | accuracy: 0.2360  loss: 2.1056 | accuracy: 0.2240  loss: 1.9843 | accuracy: 0.2600  loss: 2.0423 | accuracy: 0.2600  loss: 2.0180 | accuracy: 0.2320  loss: 2.0750 | accuracy: 0.2600  loss: 2.0789 | accuracy: 0.2520  loss: 2.0764 | accuracy: 0.2440  loss: 2.1359 | accuracy: 0.2720  loss: 2.1547 | accuracy: 0.2600  loss: 2.0212 | accuracy: 0.2440  loss: 2.1053 | accuracy: 0.2640  loss: 2.0801 | accuracy: 0.2560  loss: 2.2024 | accuracy: 0.2760  loss: 2.0461 | accuracy: 0.2320  loss: 2.0219 | accuracy: 0.2920  loss: 2.0349 | accuracy: 0.2480 \n",
      "Epoch: 1 step: 950[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]2.0769 | accuracy: 0.2720  loss: 1.9784 | accuracy: 0.2440  loss: 2.0704 | accuracy: 0.2680  loss: 1.7716 | accuracy: 0.2440  loss: 2.0430 | accuracy: 0.2640  loss: 2.4108 | accuracy: 0.2800  loss: 1.9709 | accuracy: 0.2400  loss: 2.0339 | accuracy: 0.2440  loss: 2.0072 | accuracy: 0.2760  loss: 2.0162 | accuracy: 0.2480  loss: 2.1102 | accuracy: 0.2520  loss: 2.1025 | accuracy: 0.2280  loss: 2.2646 | accuracy: 0.2320  loss: 1.9792 | accuracy: 0.2400  loss: 1.9926 | accuracy: 0.2640  loss: 2.0538 | accuracy: 0.2320  loss: 2.0532 | accuracy: 0.2880  loss: 2.1602 | accuracy: 0.2520  loss: 1.9182 | accuracy: 0.2520 \n",
      "\n",
      "--kill worse 2\n",
      "DNA [ 2 ]销毁->fitness 0.248\n",
      "pop sum:  4 | ( 0 -> 0 ) ( 1 -> 1 ) ( 2 -> 3 ) ( 3 -> 4 ) \n",
      "--reproduce better 3\n",
      "outputs_mutable 0 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_vertex() takes from 2 to 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf7c881b6224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# test = Evolution_pop(train_loader, test_x, test_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvolution_pop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_varition_dna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-9de5af1b5a51>\u001b[0m in \u001b[0;36mchoose_varition_dna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_population_size_setpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--reproduce better\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter_individual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reproduce_and_train_individual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbetter_individual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_kill_individual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9de5af1b5a51>\u001b[0m in \u001b[0;36m_reproduce_and_train_individual\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[0mson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minherit_DNA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstruct_mutation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;31m# debug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9de5af1b5a51>\u001b[0m in \u001b[0;36mmutate\u001b[1;34m(self, dna)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;31m# self.mutate_vertex(mutated_dna)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutate_vertex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutated_dna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmutated_dna\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9de5af1b5a51>\u001b[0m in \u001b[0;36mmutate_vertex\u001b[1;34m(self, dna)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0medge_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'conv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mmutated_dna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_vertex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafter_vertex_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_vertex_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertex_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmutated_dna\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add_vertex() takes from 2 to 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = MadeDate()\n",
    "    # data.mnist()\n",
    "    # 数据集选择\n",
    "    # train_loader, test_x, test_y = data.getData()\n",
    "    # train_loader, test_x, test_y = data.mnist()\n",
    "    train_loader, testloader = data.CIFR10()\n",
    "\n",
    "    # test = Evolution_pop(train_loader, test_x, test_y)\n",
    "    test = Evolution_pop(data)\n",
    "    test.choose_varition_dna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
